{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mengmengwoo/CNN-LSTM-GAN/blob/main/WGAN_GP_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Author\n",
        "- **Meng-Hsuan (Michelle) Wu** (JHU)\n",
        "\n",
        "## Projects\n",
        "- CNN-LSTM Generative Adversarial Network with Wasserstein Gradient Penalty Loss"
      ],
      "metadata": {
        "id": "6-lmnHrNAs5t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K7SIv-uw7Qt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f10007-eb56-4978-9134-b78937c00b01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import os.path\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as fn\n",
        "import torch.nn as nn\n",
        "from torch import linalg as LA\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad as torch_grad\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import math\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import pickle\n",
        "import shutil\n",
        "from torchvision.utils import make_grid\n",
        "import imageio\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from matplotlib import cm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuBvBJC6eBds"
      },
      "source": [
        "# Model (Generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwFE4LdpgCBf"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size = 2, stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(64,momentum=0.9),\n",
        "        nn.MaxPool2d(2),\n",
        "\n",
        "        nn.Conv2d(64, 128, kernel_size = 3, stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(128,momentum=0.9),\n",
        "        nn.MaxPool2d(3),\n",
        "\n",
        "        nn.Conv2d(128, 256, kernel_size = 2, stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(256,momentum=0.9),\n",
        "        nn.MaxPool2d(3),\n",
        "\n",
        "        nn.Conv2d(256, 256, kernel_size = 2, stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(256,momentum=0.9),\n",
        "        nn.MaxPool2d(3),\n",
        "\n",
        "        nn.Conv2d(256, 512, kernel_size = 3, stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    cnn_val = self.network(x)\n",
        "    return_val = F.max_pool2d(cnn_val, kernel_size=cnn_val.size()[2:])\n",
        "    return_val = torch.squeeze(return_val)\n",
        "    return return_val"
      ],
      "metadata": {
        "id": "8Bo4zUpEqA9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H55vd3TYgkv2"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.convNN = ConvNN()\n",
        "    self.lstm = nn.LSTM(input_size = 512, hidden_size = 512,\n",
        "                        batch_first = True, bidirectional = True,\n",
        "                        num_layers = 4, dropout = 0.2)\n",
        "\n",
        "  def forward(self, input):\n",
        "    batch_size = int(input.shape[0]/img_length)\n",
        "\n",
        "\n",
        "    in_features = self.convNN(input)\n",
        "    in_features = torch.reshape(in_features,(batch_size, img_length, 512))\n",
        "    output, (h_n, c_n) = self.lstm(in_features)\n",
        "    return h_n[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdaXG3I5f7u4"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aK6ivYlugAZ0"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels = 512, out_channels = 256,\n",
        "                               kernel_size = 4, stride = 1, padding = 0,\n",
        "                               bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "            nn.BatchNorm2d(256),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "            nn.BatchNorm2d(128),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 128, 4, 2, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "            nn.BatchNorm2d(128),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "            nn.BatchNorm2d(64),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
        "            nn.Sigmoid()\n",
        "\n",
        "        )\n",
        "    def forward(self, input):\n",
        "      return self.main(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator (Critic)"
      ],
      "metadata": {
        "id": "FXRHV4dyRsBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, img_size, dim):\n",
        "\n",
        "      super(Discriminator, self).__init__()\n",
        "\n",
        "      self.img_size = img_size\n",
        "\n",
        "      self.image_to_features = nn.Sequential(\n",
        "          nn.Conv2d(self.img_size[2], dim, 4, 2, 1),\n",
        "          nn.LeakyReLU(0.2),\n",
        "          nn.Conv2d(dim, 2 * dim, 4, 2, 1),\n",
        "          nn.LeakyReLU(0.2),\n",
        "          nn.Conv2d(2 * dim, 4 * dim, 4, 2, 1),\n",
        "          nn.LeakyReLU(0.2),\n",
        "          nn.Conv2d(4 * dim, 8 * dim, 4, 2, 1),\n",
        "          nn.LeakyReLU(0.2),\n",
        "          nn.Conv2d(8 * dim, self.img_size[2], 4, 2, 1),\n",
        "          nn.Sigmoid()\n",
        "      )\n",
        "\n",
        "      self.features_to_prob = nn.Sequential(\n",
        "          nn.Linear(192, 1),\n",
        "          nn.Sigmoid()\n",
        "      )\n",
        "\n",
        "  def forward(self, input_data):\n",
        "    batch_size = input_data.size()[0]\n",
        "    n_channels = input_data.size()[1]\n",
        "    x = self.image_to_features(input_data)\n",
        "    x = x.view(batch_size, -1)\n",
        "    return self.features_to_prob(x)\n"
      ],
      "metadata": {
        "id": "kUniimJCR3NU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TesEADzsglMZ"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4adeccjTJyv"
      },
      "outputs": [],
      "source": [
        "class CLSTM(nn.Module):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(CLSTM, self).__init__()\n",
        "    self.encoder = Encoder()\n",
        "    self.decoder = Decoder()\n",
        "    self.latent_dim = latent_dim\n",
        "  def forward(self, x):\n",
        "    y_hidden = self.encoder(x)\n",
        "    y_hidden = torch.unsqueeze(y_hidden,2)\n",
        "    y_hidden = torch.unsqueeze(y_hidden,3)\n",
        "    y_predict = self.decoder(y_hidden)\n",
        "    return y_predict\n",
        "  def sample_latent(self, num_samples):\n",
        "    return torch.randn((num_samples, self.latent_dim))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmHw4HIvkSaR"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reference: https://github.com/EmilienDupont/wgan-gp\n",
        "class Trainer():\n",
        "  def __init__(self, clstm, discriminator, gen_optimizer, dis_optimizer, train_losses,\n",
        "               val_losses, criterion, valid_min, checkpoint_path, best_model_path,\n",
        "              gp_weight=10, critic_iterations=1, print_every=10,\n",
        "               use_cuda=True):\n",
        "    self.G = clstm\n",
        "    self.G_opt = gen_optimizer\n",
        "    self.D = discriminator\n",
        "    self.D_opt = dis_optimizer\n",
        "    self.train_losses = train_losses\n",
        "    self.val_losses = val_losses\n",
        "    self.criterion = criterion\n",
        "    self.num_steps = 0\n",
        "    self.use_cuda = use_cuda\n",
        "\n",
        "    self.valid_mse_min = valid_min\n",
        "    self.checkpoint_path = checkpoint_path\n",
        "    self.best_model_path = best_model_path\n",
        "\n",
        "    self.gp_weight = gp_weight\n",
        "    self.critic_iterations = critic_iterations\n",
        "    self.print_every = print_every\n",
        "\n",
        "    self.temp_train_mse = []\n",
        "    self.temp_val_mse = []\n",
        "\n",
        "    if self.use_cuda:\n",
        "        self.G = self.G.cuda()\n",
        "        self.D = self.D.cuda()\n",
        "\n",
        "\n",
        "  def _critic_train_iteration(self, y_pred, y_true, train):\n",
        "    # Get generated data\n",
        "    batch_size = y_true.size()[0]\n",
        "\n",
        "    # Calculate probabilities on real and generated data\n",
        "    d_real = self.D(y_true)\n",
        "    d_generated = self.D(y_pred)\n",
        "\n",
        "\n",
        "    # Create total loss and optimize\n",
        "    if train:\n",
        "      # Get gradient penalty\n",
        "      gradient_penalty = self._gradient_penalty(y_true, y_pred, train)\n",
        "\n",
        "      self.D_opt.zero_grad()\n",
        "      d_real = d_real.view(batch_size, -1)\n",
        "      d_generated = d_generated.view(batch_size,-1)\n",
        "\n",
        "      d_loss = torch.mean(d_generated) - torch.mean(d_real) + gradient_penalty\n",
        "\n",
        "      d_loss.backward(retain_graph = True)\n",
        "      self.D_opt.step()\n",
        "\n",
        "      self.train_losses['D'].append(d_loss.data.cpu().numpy())\n",
        "    else:\n",
        "      d_real = d_real.view(batch_size, -1)\n",
        "      d_generated = d_generated.view(batch_size,-1)\n",
        "      d_loss = torch.mean(d_generated) - torch.mean(d_real)\n",
        "      self.val_losses['val_D'].append(d_loss.data.cpu().numpy())\n",
        "\n",
        "\n",
        "  def _gradient_penalty(self, real_data, generated_data, train):\n",
        "\n",
        "    batch_size = real_data.size()[0]\n",
        "    n_channels = real_data.size()[1]\n",
        "\n",
        "    # Calculate interpolation\n",
        "    epsilon = torch.rand(batch_size, 1, 1, 1)\n",
        "    epsilon = epsilon.expand_as(real_data) # make alpha the same length as real_data\n",
        "\n",
        "    if self.use_cuda:\n",
        "        epsilon = epsilon.cuda()\n",
        "    interpolated = epsilon * real_data.data + (1 - epsilon) * generated_data.data # this is x_hat\n",
        "    if train:\n",
        "      interpolated = interpolated.clone().detach().requires_grad_(True)\n",
        "    if self.use_cuda:\n",
        "        interpolated = interpolated.cuda()\n",
        "\n",
        "    # Calculate probability of interpolated examples\n",
        "    prob_interpolated = self.D(interpolated)\n",
        "\n",
        "    # Calculate gradients of probabilities with respect to examples\n",
        "    gradients = torch_grad(outputs=prob_interpolated, inputs=interpolated,\n",
        "                            grad_outputs=torch.ones(prob_interpolated.size()).cuda() if self.use_cuda else torch.ones(\n",
        "                            prob_interpolated.size()),\n",
        "                            create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "    grad_norm = LA.norm(gradients)+1e-12\n",
        "    if train:\n",
        "      self.train_losses['gradient_norm'].append(LA.norm(gradients).mean().item())\n",
        "\n",
        "    # Return gradient penalty\n",
        "    return self.gp_weight * ((grad_norm - 1) ** 2)\n",
        "  def _generator_train_iteration(self, y_pred, y_true, train):\n",
        "    if train:\n",
        "      self.G_opt.zero_grad()\n",
        "\n",
        "      # Get generated data\n",
        "      batch_size = y_true.size()[0]\n",
        "\n",
        "      # Calculate loss and optimize\n",
        "      d_generated = self.D(y_pred)\n",
        "      g_loss = - d_generated.mean()\n",
        "      g_loss.backward()\n",
        "      self.G_opt.step()\n",
        "\n",
        "      # Record loss\n",
        "      g_loss = g_loss.data.cpu().numpy()\n",
        "      self.train_losses['G'].append(g_loss)\n",
        "    else:\n",
        "      # Get generated data\n",
        "      batch_size = y_true.size()[0]\n",
        "\n",
        "      # Calculate loss and optimize\n",
        "      d_generated = self.D(y_pred)\n",
        "      g_loss = - d_generated.mean()\n",
        "\n",
        "      # Record loss\n",
        "      g_loss = g_loss.data.cpu().numpy()\n",
        "      self.val_losses['val_G'].append(g_loss)\n",
        "  def _train_epoch(self,train_loader):\n",
        "    for i, batch_train in enumerate(train_loader):\n",
        "      self.num_steps +=1\n",
        "      x_train = batch_train[:,:-1,:,:,:]\n",
        "      y_train = batch_train[:,-1,:,:,:]\n",
        "      if self.use_cuda:\n",
        "        x_train, y_train = x_train.cuda(), y_train.cuda()\n",
        "\n",
        "      n_series = x_train.shape[0]\n",
        "      n_img_in_series = x_train.shape[1]\n",
        "      img_channels = x_train.shape[2]\n",
        "      img_height = x_train.shape[3]\n",
        "      img_width = x_train.shape[4]\n",
        "\n",
        "      x_train_new_dim = (n_series*n_img_in_series, img_channels, img_height, img_width)\n",
        "      x_train = torch.reshape(x_train,x_train_new_dim)\n",
        "      y_train_predict = self.G(x_train)\n",
        "      y_train_crop = fn.center_crop(y_train, output_size=[256])\n",
        "      y_train_predict_crop = fn.center_crop(y_train_predict, output_size = [256])\n",
        "      pixel_diff = self.criterion(y_train_crop, y_train_predict_crop).cpu().detach().numpy()\n",
        "      self.temp_train_mse.append(pixel_diff)\n",
        "\n",
        "      self._critic_train_iteration(y_train_predict_crop, y_train_crop, train = True)\n",
        "      if self.num_steps % self.critic_iterations == 0:\n",
        "        self._generator_train_iteration(y_train_predict_crop, y_train_crop, train = True)\n",
        "  def _validate(self, val_loader):\n",
        "    self.G.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch_val in val_loader:\n",
        "        x_val = batch_val[:,:-1,:,:,:]\n",
        "        y_val = batch_val[:,-1,:,:,:]\n",
        "        if self.use_cuda:\n",
        "          x_val, y_val = x_val.cuda(), y_val.cuda()\n",
        "\n",
        "\n",
        "        n_series_val = x_val.shape[0]\n",
        "        n_img_in_series_val = x_val.shape[1]\n",
        "        img_channels_val = x_val.shape[2]\n",
        "        img_height_val = x_val.shape[3]\n",
        "        img_width_val = x_val.shape[4]\n",
        "\n",
        "        x_val_new_dim = (n_series_val*n_img_in_series_val, img_channels_val, img_height_val, img_width_val)\n",
        "        x_val = torch.reshape(x_val,x_val_new_dim)\n",
        "\n",
        "        y_val_predict = self.G(x_val)\n",
        "        y_val_crop = fn.center_crop(y_val, output_size=[256])\n",
        "        y_val_predict_crop = fn.center_crop(y_val_predict, output_size = [256])\n",
        "        pixel_diff = self.criterion(y_val_crop, y_val_predict_crop).cpu().detach().numpy()\n",
        "        self.temp_val_mse.append(pixel_diff)\n",
        "        self._critic_train_iteration(y_val_predict_crop, y_val_crop, train = False)\n",
        "        self._generator_train_iteration(y_val_predict_crop, y_val_crop, train = False)\n",
        "\n",
        "  def train(self, train_loader, start_epochs, n_epochs, validate_loader):\n",
        "    for epoch in range(start_epochs, n_epochs):\n",
        "      self.G.train()\n",
        "      self._train_epoch(train_loader)\n",
        "      self._validate(validate_loader)\n",
        "      avg_train_mse = sum(self.temp_train_mse)/len(self.temp_train_mse)\n",
        "      avg_val_mse = sum(self.temp_val_mse)/len(self.temp_val_mse)\n",
        "      self.train_losses['train_mse'].append(avg_train_mse)\n",
        "      self.val_losses['val_mse'].append(avg_val_mse)\n",
        "\n",
        "      if epoch % self.print_every == 0:\n",
        "        print(\"Iteration {}\".format(epoch + 1))\n",
        "        print(\"D: {}\".format(self.train_losses['D'][-1]))\n",
        "        print(\"val_D: {}\".format(self.val_losses['val_D'][-1]))\n",
        "        print(\"train_mse:{}\".format(self.train_losses['train_mse'][-1]))\n",
        "        if self.num_steps > self.critic_iterations:\n",
        "            print(\"G: {}\".format(self.train_losses['G'][-1]))\n",
        "            print(\"val_G: {}\".format(self.val_losses['val_G'][-1]))\n",
        "            print(\"val_mse:{}\".format(self.val_losses['val_mse'][-1]))\n",
        "\n",
        "      ##############\n",
        "      # checkpoint #\n",
        "      ##############\n",
        "      curr_val_mse = self.val_losses['val_mse'][-1]\n",
        "      if curr_val_mse <= self.valid_mse_min:\n",
        "        new_valid_mse_min = curr_val_mse\n",
        "      else:\n",
        "        new_valid_mse_min = self.valid_mse_min\n",
        "      if self.use_cuda:\n",
        "        self.G, self.D = self.G.cpu(), self.D.cpu()\n",
        "      checkpoint = {\n",
        "        'epoch': epoch + 1,\n",
        "        'train_loss': self.train_losses,\n",
        "        'val_loss': self.val_losses,\n",
        "        'generator_state_dict': self.G.state_dict(),\n",
        "        'generator_optimizer': self.G_opt.state_dict(),\n",
        "        'discriminator_state_dict': self.D.state_dict(),\n",
        "        'discriminator_optimizer': self.D_opt.state_dict(),\n",
        "        'lowest_val_loss': new_valid_mse_min\n",
        "        }\n",
        "      # save checkpoint\n",
        "      save_ckp(checkpoint, False, self.checkpoint_path, self.best_model_path)\n",
        "\n",
        "\n",
        "      # save the model if validation loss has decreased\n",
        "      if curr_val_mse <= self.valid_mse_min:\n",
        "          print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(self.valid_mse_min,curr_val_mse))\n",
        "          # save checkpoint as best model\n",
        "          save_ckp(checkpoint, True, self.checkpoint_path, self.best_model_path)\n",
        "          self.valid_mse_min = curr_val_mse\n",
        "\n",
        "      self.temp_train_mse = []\n",
        "      self.temp_val_mse = []\n",
        "      if self.use_cuda:\n",
        "        self.G, self.D = self.G.cuda(), self.D.cuda()\n",
        "\n"
      ],
      "metadata": {
        "id": "YJC6g3cUgNJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzdRvV12o8xE"
      },
      "source": [
        "# Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRaE2Ci5o_u6"
      },
      "outputs": [],
      "source": [
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "  f_path = checkpoint_path\n",
        "  torch.save(state, f_path)\n",
        "  if is_best:\n",
        "      print(\"Saving a new best model\")\n",
        "      best_fpath = best_model_path\n",
        "      # copy that checkpoint file to best path given, best_model_path\n",
        "      shutil.copyfile(f_path, best_fpath)\n",
        "  else:\n",
        "    print('Validation does not improve')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLJe-iq3a4PC"
      },
      "outputs": [],
      "source": [
        "def load_ckp(checkpoint_fpath, gen_model, gen_opt, discrim_model, discrim_opt):\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "    # load check point\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    # initialize state_dict from checkpoint to model\n",
        "    gen_model.load_state_dict(checkpoint['generator_state_dict'])\n",
        "    discrim_model.load_state_dict(checkpoint['discriminator_state_dict'])\n",
        "    gen_model = gen_model.to(device)\n",
        "    discrim_model = discrim_model.to(device)\n",
        "    # initialize optimizer from checkpoint to optimizer\n",
        "    gen_opt.load_state_dict(checkpoint['generator_optimizer'])\n",
        "    discrim_opt.load_state_dict(checkpoint['discriminator_optimizer'])\n",
        "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
        "    train_loss_lst = checkpoint['train_loss']\n",
        "    valid_loss_lst = checkpoint['val_loss']\n",
        "    print(valid_loss_lst)\n",
        "    lowest_val_loss = checkpoint['lowest_val_loss']\n",
        "\n",
        "    return checkpoint['epoch'], gen_model, discrim_model, gen_opt, discrim_opt, train_loss_lst,valid_loss_lst, lowest_val_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6EnGnLFgnke"
      },
      "source": [
        "# Setting Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Datapoint"
      ],
      "metadata": {
        "id": "Y8-QBpuuPRsf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tjffzEIWfQk"
      },
      "outputs": [],
      "source": [
        "# convert the image to array\n",
        "x_img_length = 2\n",
        "\n",
        "x_arr = np.zeros(shape=(100,x_img_length, 3,288,432), dtype=np.uint8)\n",
        "y_arr = np.zeros(shape=(100,1,3,288,432), dtype=np.uint8)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(100): # loop through 100 series\n",
        "  for j in range(x_img_length): # loop through images within series\n",
        "    model_path = \"/content/drive/MyDrive/Capstone/Capstone_data_jpg/\"+str(i)\n",
        "    x_to_convert = Image.open(model_path+'/'+\"{:02d}\".format(j)+'im.jpg')\n",
        "    x = np.asarray(x_to_convert)\n",
        "    x = np.moveaxis(x,-1,0) # change image dimension to channel first\n",
        "    x_arr[i][j] = x\n",
        "  y_to_convert = Image.open(model_path+'/'+\"{:02d}\".format(x_img_length+1)+'im.jpg')\n",
        "  y = np.asarray(y_to_convert)\n",
        "  y = np.moveaxis(y,-1,0) # change image dimension to channel first\n",
        "  y_arr[i][0] = y\n",
        "\n",
        "# image dimention\n",
        "n_series = x_arr.shape[0]\n",
        "n_img_in_series = x_arr.shape[1]\n",
        "img_channels = x_arr.shape[2]\n",
        "img_height = x_arr.shape[3]\n",
        "img_width = x_arr.shape[4]\n",
        "\n",
        "# train/validation/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_arr, y_arr, test_size = 0.2, random_state = 1)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5, random_state = 1)\n",
        "\n",
        "num_train_data = X_train.shape[0]\n",
        "num_val_data = X_val.shape[0]\n",
        "num_test_data = X_test.shape[0]\n",
        "\n",
        "# generating means and std for normalization\n",
        "trans_X_train= torch.tensor((np.array(X_train)/255).astype(np.float32))\n",
        "trans_y_train = torch.tensor((np.array(y_train)/255).astype(np.float32))\n",
        "trans_X_val = torch.tensor((np.array(X_val)/255).astype(np.float32))\n",
        "trans_y_val = torch.tensor((np.array(y_val)/255).astype(np.float32))\n",
        "trans_X_test = torch.tensor((np.array(X_test)/255).astype(np.float32))\n",
        "trans_y_test = torch.tensor((np.array(y_test)/255).astype(np.float32))\n",
        "\n",
        "\n",
        "# final train/val/test data\n",
        "final_train_data = torch.cat((trans_X_train, trans_y_train), dim = 1)\n",
        "final_val_data = torch.cat((trans_X_val,trans_y_val),dim = 1)\n",
        "final_test_data = torch.cat((trans_X_test,trans_y_test),dim = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQxYsRndGPq9"
      },
      "outputs": [],
      "source": [
        "batch_train_num = 8\n",
        "batch_valid_num = 10\n",
        "batch_test_num= 10\n",
        "\n",
        "train_dl = DataLoader(final_train_data, batch_train_num, shuffle = True)\n",
        "val_dl = DataLoader(final_val_data, batch_valid_num, shuffle = True)\n",
        "test_dl = DataLoader(final_test_data, batch_test_num, shuffle = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling Train"
      ],
      "metadata": {
        "id": "dYdY3hzjPXXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "\n",
        "# setting parameters\n",
        "x_img_length = 2\n",
        "img_length = x_img_length\n",
        "clstm = CLSTM(512)\n",
        "img_size = (288, 432, 3)\n",
        "discriminator = Discriminator(img_size=img_size, dim=16)\n",
        "criterion = nn.MSELoss()\n",
        "print(clstm)\n",
        "print(discriminator)\n",
        "\n",
        "# Initialize optimizers\n",
        "lr = 0.00001\n",
        "betas = (.9, .99)\n",
        "g_optimizer = optim.RMSprop(clstm.parameters(), lr = lr)\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr = lr)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "start_epochs = 0\n",
        "n_epochs = 5\n",
        "\n",
        "valid_loss_min_input = np.Inf\n",
        "train_losses = {'G': [], 'D': [], 'GP': [], 'gradient_norm': [], \"train_mse\" :[]}\n",
        "val_losses = {'val_G': [], 'val_D': [], \"val_mse\":[]}\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/Capstone/Capstone_checkpoint_models/clstm_wasser_upsample_opti_1000_final_2.pt\"\n",
        "best_model_path = \"/content/drive/MyDrive/Capstone/Capstone_models/clstm_wasser_upsample_opti_best_final_2.pt\"\n",
        "\n",
        "trainer = Trainer(clstm, discriminator, g_optimizer, d_optimizer,train_losses,val_losses,criterion,\n",
        "                  valid_loss_min_input, checkpoint_path, best_model_path,\n",
        "                  gp_weight = 10, use_cuda=torch.cuda.is_available())\n"
      ],
      "metadata": {
        "id": "-0uvMcnLWAVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3122d6ec-a6f6-421e-b630-0dfc74789e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLSTM(\n",
            "  (encoder): Encoder(\n",
            "    (convNN): ConvNN(\n",
            "      (network): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (5): ReLU()\n",
            "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (7): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "        (8): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (9): ReLU()\n",
            "        (10): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (11): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "        (12): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (13): ReLU()\n",
            "        (14): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (15): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "        (16): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (17): ReLU()\n",
            "        (18): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (lstm): LSTM(512, 512, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (main): Sequential(\n",
            "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "      (1): ReLU()\n",
            "      (2): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (4): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (5): ReLU()\n",
            "      (6): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (8): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (9): ReLU()\n",
            "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (12): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (13): ReLU()\n",
            "      (14): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (16): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (17): Sigmoid()\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Discriminator(\n",
            "  (image_to_features): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): LeakyReLU(negative_slope=0.2)\n",
            "    (4): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "    (6): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (7): LeakyReLU(negative_slope=0.2)\n",
            "    (8): Conv2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (9): Sigmoid()\n",
            "  )\n",
            "  (features_to_prob): Sequential(\n",
            "    (0): Linear(in_features=192, out_features=1, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2k-9tnynux6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93874579-4f50-4d3e-c796-820dc7cdbffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'val_G': [array(-0.5677058, dtype=float32), array(-0.56679225, dtype=float32), array(-0.56585723, dtype=float32), array(-0.5649588, dtype=float32), array(-0.5642179, dtype=float32), array(-0.5641148, dtype=float32), array(-0.56479704, dtype=float32), array(-0.5662947, dtype=float32), array(-0.56859183, dtype=float32), array(-0.5709512, dtype=float32), array(-0.57240385, dtype=float32), array(-0.57290155, dtype=float32), array(-0.57298523, dtype=float32), array(-0.57292265, dtype=float32), array(-0.57285136, dtype=float32), array(-0.57279354, dtype=float32), array(-0.57273996, dtype=float32), array(-0.5726987, dtype=float32), array(-0.5726652, dtype=float32), array(-0.57263947, dtype=float32), array(-0.5726347, dtype=float32), array(-0.5726411, dtype=float32), array(-0.57266617, dtype=float32), array(-0.5727444, dtype=float32), array(-0.57286733, dtype=float32), array(-0.5730422, dtype=float32), array(-0.573248, dtype=float32), array(-0.5734467, dtype=float32), array(-0.5736427, dtype=float32), array(-0.5738528, dtype=float32), array(-0.57411003, dtype=float32), array(-0.57439566, dtype=float32), array(-0.57472193, dtype=float32), array(-0.57505083, dtype=float32), array(-0.5753789, dtype=float32), array(-0.5757004, dtype=float32), array(-0.5759954, dtype=float32), array(-0.5762886, dtype=float32), array(-0.57657653, dtype=float32), array(-0.57685405, dtype=float32), array(-0.57714766, dtype=float32), array(-0.57742137, dtype=float32), array(-0.5776574, dtype=float32), array(-0.57792073, dtype=float32), array(-0.5781972, dtype=float32), array(-0.5784828, dtype=float32), array(-0.5787836, dtype=float32), array(-0.57903856, dtype=float32), array(-0.5793277, dtype=float32), array(-0.5795991, dtype=float32), array(-0.579834, dtype=float32), array(-0.58006054, dtype=float32), array(-0.58028257, dtype=float32), array(-0.580502, dtype=float32), array(-0.580698, dtype=float32), array(-0.58092207, dtype=float32), array(-0.58118886, dtype=float32), array(-0.5814524, dtype=float32), array(-0.5817179, dtype=float32), array(-0.5819974, dtype=float32), array(-0.5822719, dtype=float32), array(-0.58254063, dtype=float32), array(-0.58280665, dtype=float32), array(-0.583064, dtype=float32), array(-0.58335334, dtype=float32), array(-0.5836437, dtype=float32), array(-0.5839267, dtype=float32), array(-0.58421403, dtype=float32), array(-0.5845128, dtype=float32), array(-0.5847921, dtype=float32), array(-0.5850442, dtype=float32), array(-0.585312, dtype=float32), array(-0.58554524, dtype=float32), array(-0.5857979, dtype=float32), array(-0.5860158, dtype=float32), array(-0.5862473, dtype=float32), array(-0.5865006, dtype=float32), array(-0.5867819, dtype=float32), array(-0.587132, dtype=float32), array(-0.5874826, dtype=float32), array(-0.5878727, dtype=float32), array(-0.5882514, dtype=float32), array(-0.5886242, dtype=float32), array(-0.58900404, dtype=float32), array(-0.58935636, dtype=float32), array(-0.5897183, dtype=float32), array(-0.5900836, dtype=float32), array(-0.5904488, dtype=float32), array(-0.5907993, dtype=float32), array(-0.59113204, dtype=float32), array(-0.59148973, dtype=float32), array(-0.5918235, dtype=float32), array(-0.59218276, dtype=float32), array(-0.5925548, dtype=float32), array(-0.59291327, dtype=float32), array(-0.5932934, dtype=float32), array(-0.5936753, dtype=float32), array(-0.59406435, dtype=float32), array(-0.5944278, dtype=float32), array(-0.5948421, dtype=float32), array(-0.595211, dtype=float32), array(-0.5955847, dtype=float32), array(-0.595977, dtype=float32), array(-0.59634, dtype=float32), array(-0.5967332, dtype=float32), array(-0.5971615, dtype=float32), array(-0.59760344, dtype=float32), array(-0.5980245, dtype=float32), array(-0.5983841, dtype=float32), array(-0.5987877, dtype=float32), array(-0.5992004, dtype=float32), array(-0.5995855, dtype=float32), array(-0.59998465, dtype=float32), array(-0.60038847, dtype=float32), array(-0.6008008, dtype=float32), array(-0.60120815, dtype=float32), array(-0.60162014, dtype=float32), array(-0.6020189, dtype=float32), array(-0.60242414, dtype=float32), array(-0.6028021, dtype=float32), array(-0.60321444, dtype=float32), array(-0.6035982, dtype=float32), array(-0.6039672, dtype=float32), array(-0.6043789, dtype=float32), array(-0.60479003, dtype=float32), array(-0.605225, dtype=float32), array(-0.60561603, dtype=float32), array(-0.60605574, dtype=float32), array(-0.6064648, dtype=float32), array(-0.606862, dtype=float32), array(-0.6072422, dtype=float32), array(-0.60764533, dtype=float32), array(-0.6080367, dtype=float32), array(-0.60838807, dtype=float32), array(-0.6087581, dtype=float32), array(-0.60908854, dtype=float32), array(-0.60941464, dtype=float32), array(-0.60978234, dtype=float32), array(-0.6101619, dtype=float32), array(-0.6105534, dtype=float32), array(-0.61091304, dtype=float32), array(-0.61134213, dtype=float32), array(-0.6117662, dtype=float32), array(-0.61222154, dtype=float32), array(-0.6126544, dtype=float32), array(-0.6130617, dtype=float32), array(-0.6134201, dtype=float32), array(-0.61381674, dtype=float32), array(-0.61423343, dtype=float32), array(-0.6146258, dtype=float32), array(-0.61500305, dtype=float32), array(-0.615382, dtype=float32), array(-0.6157185, dtype=float32), array(-0.6161189, dtype=float32), array(-0.61647767, dtype=float32), array(-0.6169061, dtype=float32), array(-0.61730546, dtype=float32), array(-0.61770314, dtype=float32), array(-0.6181077, dtype=float32), array(-0.6185047, dtype=float32), array(-0.61892664, dtype=float32), array(-0.6192852, dtype=float32), array(-0.61963123, dtype=float32), array(-0.6200234, dtype=float32), array(-0.6203577, dtype=float32), array(-0.62070173, dtype=float32), array(-0.6210358, dtype=float32), array(-0.62138903, dtype=float32), array(-0.6217665, dtype=float32), array(-0.6221739, dtype=float32), array(-0.6225757, dtype=float32), array(-0.6229959, dtype=float32), array(-0.62338525, dtype=float32), array(-0.62377787, dtype=float32), array(-0.6241763, dtype=float32), array(-0.6246016, dtype=float32), array(-0.62499315, dtype=float32), array(-0.6254081, dtype=float32), array(-0.6256973, dtype=float32), array(-0.6260438, dtype=float32), array(-0.6263423, dtype=float32), array(-0.6267266, dtype=float32), array(-0.62714523, dtype=float32), array(-0.6275557, dtype=float32), array(-0.62793505, dtype=float32), array(-0.62834173, dtype=float32), array(-0.62869567, dtype=float32), array(-0.6291199, dtype=float32), array(-0.629535, dtype=float32), array(-0.62991244, dtype=float32), array(-0.63038534, dtype=float32), array(-0.63084, dtype=float32), array(-0.63133407, dtype=float32), array(-0.6317052, dtype=float32), array(-0.63204885, dtype=float32), array(-0.6323549, dtype=float32), array(-0.6326504, dtype=float32), array(-0.6329968, dtype=float32), array(-0.6334071, dtype=float32), array(-0.63384, dtype=float32), array(-0.63427186, dtype=float32), array(-0.63467234, dtype=float32), array(-0.6350602, dtype=float32), array(-0.6355378, dtype=float32), array(-0.63599366, dtype=float32), array(-0.63634294, dtype=float32), array(-0.6365739, dtype=float32), array(-0.6369547, dtype=float32), array(-0.63742113, dtype=float32), array(-0.63785595, dtype=float32), array(-0.6382165, dtype=float32), array(-0.63856083, dtype=float32), array(-0.63895, dtype=float32), array(-0.6393138, dtype=float32), array(-0.63968027, dtype=float32), array(-0.6401357, dtype=float32), array(-0.64052546, dtype=float32), array(-0.6409368, dtype=float32), array(-0.6413409, dtype=float32), array(-0.6417452, dtype=float32), array(-0.6421582, dtype=float32), array(-0.64255196, dtype=float32), array(-0.6429142, dtype=float32), array(-0.6433714, dtype=float32), array(-0.64383596, dtype=float32), array(-0.64416045, dtype=float32), array(-0.644505, dtype=float32), array(-0.6450116, dtype=float32), array(-0.6454352, dtype=float32), array(-0.6458127, dtype=float32), array(-0.64620936, dtype=float32), array(-0.6465916, dtype=float32), array(-0.6470129, dtype=float32), array(-0.64743215, dtype=float32), array(-0.6479154, dtype=float32), array(-0.6482687, dtype=float32), array(-0.64860934, dtype=float32), array(-0.6490533, dtype=float32), array(-0.64944935, dtype=float32), array(-0.64987403, dtype=float32), array(-0.6503142, dtype=float32), array(-0.6506749, dtype=float32), array(-0.6510486, dtype=float32), array(-0.65143913, dtype=float32), array(-0.6518716, dtype=float32), array(-0.65223455, dtype=float32), array(-0.65252626, dtype=float32), array(-0.6529037, dtype=float32), array(-0.65338224, dtype=float32), array(-0.65376055, dtype=float32), array(-0.6541811, dtype=float32), array(-0.65444916, dtype=float32), array(-0.65493834, dtype=float32), array(-0.6553346, dtype=float32), array(-0.6556963, dtype=float32), array(-0.6560475, dtype=float32), array(-0.65647644, dtype=float32), array(-0.6568684, dtype=float32), array(-0.6572799, dtype=float32), array(-0.657632, dtype=float32), array(-0.6581263, dtype=float32), array(-0.65844727, dtype=float32), array(-0.65879726, dtype=float32), array(-0.6592533, dtype=float32), array(-0.65963477, dtype=float32), array(-0.66005206, dtype=float32), array(-0.6603883, dtype=float32), array(-0.6608207, dtype=float32), array(-0.6611555, dtype=float32), array(-0.66153616, dtype=float32), array(-0.6619854, dtype=float32), array(-0.66238624, dtype=float32), array(-0.6627469, dtype=float32), array(-0.6631259, dtype=float32), array(-0.6634998, dtype=float32), array(-0.663911, dtype=float32), array(-0.664252, dtype=float32), array(-0.664683, dtype=float32), array(-0.665158, dtype=float32), array(-0.6655119, dtype=float32), array(-0.6657823, dtype=float32), array(-0.6662137, dtype=float32), array(-0.66663116, dtype=float32), array(-0.6671156, dtype=float32), array(-0.6672957, dtype=float32), array(-0.6677942, dtype=float32), array(-0.6681361, dtype=float32), array(-0.66870034, dtype=float32), array(-0.66898036, dtype=float32), array(-0.66914535, dtype=float32), array(-0.6695639, dtype=float32), array(-0.6700988, dtype=float32), array(-0.6705793, dtype=float32), array(-0.67078793, dtype=float32), array(-0.67123955, dtype=float32), array(-0.6716087, dtype=float32), array(-0.6719853, dtype=float32), array(-0.67238545, dtype=float32), array(-0.6728978, dtype=float32), array(-0.67311364, dtype=float32), array(-0.6734128, dtype=float32), array(-0.6739647, dtype=float32), array(-0.67424, dtype=float32), array(-0.6747279, dtype=float32), array(-0.675004, dtype=float32), array(-0.6752159, dtype=float32), array(-0.67563105, dtype=float32), array(-0.67613566, dtype=float32), array(-0.6764645, dtype=float32), array(-0.6767521, dtype=float32), array(-0.6769598, dtype=float32), array(-0.67738056, dtype=float32), array(-0.6777672, dtype=float32), array(-0.6780348, dtype=float32), array(-0.67820823, dtype=float32), array(-0.6785838, dtype=float32), array(-0.6788632, dtype=float32), array(-0.6789827, dtype=float32), array(-0.6793427, dtype=float32), array(-0.6795842, dtype=float32), array(-0.6797016, dtype=float32), array(-0.6798731, dtype=float32), array(-0.6800553, dtype=float32), array(-0.6804282, dtype=float32), array(-0.6803946, dtype=float32), array(-0.6804814, dtype=float32), array(-0.68029857, dtype=float32), array(-0.68076575, dtype=float32), array(-0.68100715, dtype=float32), array(-0.68054396, dtype=float32), array(-0.68047667, dtype=float32), array(-0.6813401, dtype=float32), array(-0.6807707, dtype=float32), array(-0.6802355, dtype=float32), array(-0.6816999, dtype=float32), array(-0.6799655, dtype=float32), array(-0.67961425, dtype=float32), array(-0.6831833, dtype=float32), array(-0.68154526, dtype=float32), array(-0.6768919, dtype=float32), array(-0.67793924, dtype=float32), array(-0.6782273, dtype=float32), array(-0.6806966, dtype=float32), array(-0.68207735, dtype=float32), array(-0.6774641, dtype=float32), array(-0.67551774, dtype=float32), array(-0.67540926, dtype=float32), array(-0.67600024, dtype=float32), array(-0.6769857, dtype=float32), array(-0.677679, dtype=float32), array(-0.6766291, dtype=float32), array(-0.67576355, dtype=float32), array(-0.6757971, dtype=float32), array(-0.6761172, dtype=float32), array(-0.6766819, dtype=float32), array(-0.67741853, dtype=float32), array(-0.67687714, dtype=float32), array(-0.6758812, dtype=float32), array(-0.67574084, dtype=float32), array(-0.6757286, dtype=float32), array(-0.67587435, dtype=float32), array(-0.67636496, dtype=float32), array(-0.6754608, dtype=float32), array(-0.6745026, dtype=float32), array(-0.6743765, dtype=float32), array(-0.6744435, dtype=float32), array(-0.6747214, dtype=float32), array(-0.67522275, dtype=float32), array(-0.67404884, dtype=float32), array(-0.67342454, dtype=float32), array(-0.6733339, dtype=float32), array(-0.6734449, dtype=float32), array(-0.6738027, dtype=float32), array(-0.674234, dtype=float32), array(-0.6732362, dtype=float32), array(-0.6727583, dtype=float32), array(-0.6726423, dtype=float32), array(-0.6726777, dtype=float32), array(-0.6729583, dtype=float32), array(-0.6732134, dtype=float32), array(-0.6722152, dtype=float32), array(-0.6717658, dtype=float32), array(-0.67165244, dtype=float32), array(-0.6716616, dtype=float32), array(-0.6719, dtype=float32), array(-0.67204267, dtype=float32), array(-0.6712986, dtype=float32), array(-0.6709704, dtype=float32), array(-0.67090005, dtype=float32), array(-0.6709594, dtype=float32), array(-0.67123634, dtype=float32), array(-0.67101616, dtype=float32), array(-0.67034775, dtype=float32), array(-0.67020196, dtype=float32), array(-0.6701957, dtype=float32), array(-0.670367, dtype=float32), array(-0.67039084, dtype=float32), array(-0.66972893, dtype=float32), array(-0.66956013, dtype=float32), array(-0.66958255, dtype=float32), array(-0.6697978, dtype=float32), array(-0.6697506, dtype=float32), array(-0.6692606, dtype=float32), array(-0.66918826, dtype=float32), array(-0.6692664, dtype=float32), array(-0.6695771, dtype=float32), array(-0.6692041, dtype=float32), array(-0.6688536, dtype=float32), array(-0.6688468, dtype=float32), array(-0.6690023, dtype=float32), array(-0.6691726, dtype=float32), array(-0.668663, dtype=float32), array(-0.66855174, dtype=float32), array(-0.66863126, dtype=float32), array(-0.66895586, dtype=float32), array(-0.6686799, dtype=float32), array(-0.6683483, dtype=float32), array(-0.66834277, dtype=float32), array(-0.6685068, dtype=float32), array(-0.66873795, dtype=float32), array(-0.6682011, dtype=float32), array(-0.6680944, dtype=float32), array(-0.66816705, dtype=float32), array(-0.6684386, dtype=float32), array(-0.6685378, dtype=float32), array(-0.6680443, dtype=float32), array(-0.66801584, dtype=float32), array(-0.66813326, dtype=float32), array(-0.66848445, dtype=float32), array(-0.66839, dtype=float32), array(-0.6678168, dtype=float32), array(-0.6677713, dtype=float32), array(-0.6678667, dtype=float32), array(-0.6681638, dtype=float32), array(-0.66813326, dtype=float32), array(-0.6675698, dtype=float32), array(-0.6675264, dtype=float32), array(-0.6675894, dtype=float32), array(-0.6678253, dtype=float32), array(-0.66802955, dtype=float32), array(-0.6673713, dtype=float32), array(-0.66723853, dtype=float32), array(-0.6673114, dtype=float32), array(-0.66753644, dtype=float32), array(-0.66795856, dtype=float32), array(-0.6676799, dtype=float32), array(-0.66737306, dtype=float32), array(-0.66751134, dtype=float32), array(-0.66777754, dtype=float32), array(-0.6681723, dtype=float32), array(-0.6682911, dtype=float32), array(-0.6680094, dtype=float32), array(-0.668128, dtype=float32), array(-0.66842026, dtype=float32), array(-0.66883105, dtype=float32), array(-0.66914463, dtype=float32), array(-0.6687924, dtype=float32), array(-0.66882676, dtype=float32), array(-0.66910446, dtype=float32), array(-0.66954386, dtype=float32), array(-0.67003554, dtype=float32), array(-0.6699642, dtype=float32), array(-0.6700963, dtype=float32), array(-0.6703817, dtype=float32), array(-0.67081773, dtype=float32), array(-0.6712949, dtype=float32), array(-0.6715715, dtype=float32), array(-0.6717747, dtype=float32), array(-0.67213464, dtype=float32), array(-0.67266893, dtype=float32), array(-0.6730029, dtype=float32), array(-0.67342484, dtype=float32), array(-0.673824, dtype=float32), array(-0.6742833, dtype=float32), array(-0.67466754, dtype=float32), array(-0.6747488, dtype=float32), array(-0.67500454, dtype=float32), array(-0.6753878, dtype=float32), array(-0.6756868, dtype=float32), array(-0.67574775, dtype=float32), array(-0.6759016, dtype=float32), array(-0.67625874, dtype=float32), array(-0.6765704, dtype=float32), array(-0.6769053, dtype=float32), array(-0.6768481, dtype=float32), array(-0.67695457, dtype=float32), array(-0.67729425, dtype=float32), array(-0.67777467, dtype=float32), array(-0.67801064, dtype=float32), array(-0.6781852, dtype=float32), array(-0.6784648, dtype=float32), array(-0.6788392, dtype=float32), array(-0.6792364, dtype=float32), array(-0.67934054, dtype=float32), array(-0.679589, dtype=float32), array(-0.6798961, dtype=float32), array(-0.68017024, dtype=float32), array(-0.68021435, dtype=float32), array(-0.6803744, dtype=float32), array(-0.6806557, dtype=float32), array(-0.6809919, dtype=float32), array(-0.68111944, dtype=float32), array(-0.68114156, dtype=float32), array(-0.68141043, dtype=float32), array(-0.68183327, dtype=float32), array(-0.68218744, dtype=float32), array(-0.6824171, dtype=float32), array(-0.6827137, dtype=float32), array(-0.6830881, dtype=float32), array(-0.68345785, dtype=float32), array(-0.6837041, dtype=float32), array(-0.6840469, dtype=float32), array(-0.684422, dtype=float32), array(-0.6847089, dtype=float32), array(-0.6848875, dtype=float32), array(-0.6851753, dtype=float32), array(-0.6855643, dtype=float32), array(-0.6859474, dtype=float32), array(-0.68611646, dtype=float32), array(-0.68634367, dtype=float32), array(-0.68673295, dtype=float32), array(-0.6871646, dtype=float32), array(-0.6875049, dtype=float32), array(-0.68776274, dtype=float32), array(-0.6880586, dtype=float32), array(-0.6884692, dtype=float32), array(-0.68877923, dtype=float32), array(-0.68911344, dtype=float32), array(-0.68942475, dtype=float32), array(-0.6897026, dtype=float32), array(-0.6899846, dtype=float32), array(-0.6902817, dtype=float32), array(-0.6906407, dtype=float32), array(-0.6909052, dtype=float32), array(-0.691106, dtype=float32), array(-0.6914203, dtype=float32), array(-0.6917855, dtype=float32), array(-0.69211406, dtype=float32), array(-0.6923493, dtype=float32), array(-0.69263303, dtype=float32), array(-0.6929763, dtype=float32), array(-0.6933357, dtype=float32), array(-0.6936223, dtype=float32), array(-0.69388574, dtype=float32), array(-0.694208, dtype=float32), array(-0.69453573, dtype=float32), array(-0.69488543, dtype=float32), array(-0.69515085, dtype=float32), array(-0.6954359, dtype=float32), array(-0.6957836, dtype=float32), array(-0.69613665, dtype=float32), array(-0.6964717, dtype=float32), array(-0.6967486, dtype=float32), array(-0.6971009, dtype=float32), array(-0.69742984, dtype=float32), array(-0.69779617, dtype=float32), array(-0.6981022, dtype=float32), array(-0.6983976, dtype=float32), array(-0.69871306, dtype=float32), array(-0.6990773, dtype=float32), array(-0.69941956, dtype=float32), array(-0.6996834, dtype=float32), array(-0.70002055, dtype=float32), array(-0.7003654, dtype=float32), array(-0.7007367, dtype=float32), array(-0.70102715, dtype=float32), array(-0.70133966, dtype=float32), array(-0.701701, dtype=float32), array(-0.7020745, dtype=float32), array(-0.70241183, dtype=float32), array(-0.70271605, dtype=float32), array(-0.7031051, dtype=float32), array(-0.7034766, dtype=float32), array(-0.70384854, dtype=float32), array(-0.7041971, dtype=float32), array(-0.7045946, dtype=float32), array(-0.7049774, dtype=float32), array(-0.70535326, dtype=float32), array(-0.705739, dtype=float32), array(-0.7060811, dtype=float32), array(-0.7064292, dtype=float32), array(-0.70680475, dtype=float32), array(-0.7072024, dtype=float32), array(-0.7074956, dtype=float32), array(-0.707854, dtype=float32), array(-0.7082548, dtype=float32), array(-0.70865005, dtype=float32), array(-0.7090046, dtype=float32), array(-0.7093835, dtype=float32), array(-0.70978105, dtype=float32), array(-0.710134, dtype=float32), array(-0.71052116, dtype=float32), array(-0.71088266, dtype=float32), array(-0.711261, dtype=float32), array(-0.7116201, dtype=float32), array(-0.712001, dtype=float32), array(-0.71235514, dtype=float32), array(-0.71267813, dtype=float32), array(-0.7130488, dtype=float32), array(-0.71343493, dtype=float32), array(-0.71379507, dtype=float32), array(-0.7141323, dtype=float32), array(-0.71452683, dtype=float32), array(-0.7148862, dtype=float32), array(-0.7152653, dtype=float32), array(-0.7156155, dtype=float32), array(-0.71600556, dtype=float32), array(-0.7163494, dtype=float32), array(-0.716719, dtype=float32), array(-0.7170782, dtype=float32), array(-0.7174151, dtype=float32), array(-0.7177702, dtype=float32), array(-0.7181499, dtype=float32), array(-0.7185089, dtype=float32), array(-0.71885455, dtype=float32), array(-0.7192124, dtype=float32), array(-0.7195582, dtype=float32), array(-0.7199361, dtype=float32), array(-0.7202619, dtype=float32), array(-0.7206154, dtype=float32), array(-0.7209784, dtype=float32), array(-0.7213561, dtype=float32), array(-0.72167945, dtype=float32), array(-0.72200644, dtype=float32), array(-0.7224037, dtype=float32), array(-0.72277045, dtype=float32), array(-0.72310305, dtype=float32), array(-0.723457, dtype=float32), array(-0.7238309, dtype=float32), array(-0.72418374, dtype=float32), array(-0.7245448, dtype=float32), array(-0.7248964, dtype=float32), array(-0.7252547, dtype=float32), array(-0.7256296, dtype=float32), array(-0.725991, dtype=float32), array(-0.726312, dtype=float32), array(-0.7267205, dtype=float32), array(-0.72705287, dtype=float32), array(-0.7274165, dtype=float32), array(-0.7277495, dtype=float32), array(-0.72804064, dtype=float32), array(-0.7284119, dtype=float32), array(-0.72877586, dtype=float32), array(-0.7291047, dtype=float32), array(-0.72946274, dtype=float32), array(-0.7298269, dtype=float32), array(-0.73019403, dtype=float32), array(-0.7305319, dtype=float32), array(-0.7309178, dtype=float32), array(-0.73123956, dtype=float32), array(-0.73161924, dtype=float32), array(-0.7319441, dtype=float32), array(-0.73224455, dtype=float32), array(-0.73263156, dtype=float32), array(-0.7329919, dtype=float32), array(-0.7332734, dtype=float32), array(-0.7336305, dtype=float32), array(-0.73401, dtype=float32), array(-0.73432636, dtype=float32), array(-0.73469305, dtype=float32), array(-0.7350591, dtype=float32), array(-0.7353832, dtype=float32), array(-0.73575497, dtype=float32), array(-0.7360892, dtype=float32), array(-0.7363998, dtype=float32), array(-0.7367764, dtype=float32), array(-0.7371199, dtype=float32), array(-0.73740244, dtype=float32), array(-0.7377678, dtype=float32), array(-0.7381179, dtype=float32), array(-0.7384275, dtype=float32), array(-0.73876333, dtype=float32), array(-0.7391019, dtype=float32), array(-0.73945445, dtype=float32), array(-0.73977757, dtype=float32), array(-0.7401322, dtype=float32), array(-0.7404671, dtype=float32), array(-0.7408147, dtype=float32), array(-0.74115837, dtype=float32), array(-0.7414845, dtype=float32), array(-0.7418234, dtype=float32), array(-0.74218506, dtype=float32), array(-0.7424844, dtype=float32), array(-0.7427952, dtype=float32), array(-0.74318504, dtype=float32), array(-0.74346864, dtype=float32), array(-0.74379414, dtype=float32), array(-0.74416274, dtype=float32), array(-0.74448967, dtype=float32), array(-0.7448368, dtype=float32), array(-0.74520075, dtype=float32), array(-0.7455085, dtype=float32), array(-0.74587715, dtype=float32), array(-0.74621266, dtype=float32), array(-0.74646825, dtype=float32), array(-0.7468709, dtype=float32), array(-0.74713683, dtype=float32), array(-0.74745345, dtype=float32), array(-0.7478328, dtype=float32), array(-0.74810505, dtype=float32), array(-0.74847376, dtype=float32), array(-0.7487957, dtype=float32), array(-0.74906194, dtype=float32), array(-0.7494707, dtype=float32), array(-0.7496874, dtype=float32), array(-0.7500601, dtype=float32), array(-0.75034887, dtype=float32), array(-0.7506424, dtype=float32), array(-0.7510173, dtype=float32), array(-0.7512584, dtype=float32), array(-0.75162524, dtype=float32), array(-0.75192374, dtype=float32), array(-0.7522194, dtype=float32), array(-0.75259924, dtype=float32), array(-0.7528259, dtype=float32), array(-0.7532088, dtype=float32), array(-0.75347835, dtype=float32), array(-0.75377023, dtype=float32), array(-0.7541463, dtype=float32), array(-0.75438094, dtype=float32), array(-0.75475967, dtype=float32), array(-0.7550216, dtype=float32), array(-0.7553042, dtype=float32), array(-0.75568074, dtype=float32), array(-0.75588626, dtype=float32), array(-0.7562723, dtype=float32), array(-0.75651515, dtype=float32), array(-0.7568251, dtype=float32), array(-0.7571692, dtype=float32), array(-0.7574069, dtype=float32), array(-0.7577969, dtype=float32), array(-0.7580186, dtype=float32), array(-0.7583756, dtype=float32), array(-0.7586841, dtype=float32), array(-0.7589595, dtype=float32), array(-0.759336, dtype=float32), array(-0.7595689, dtype=float32), array(-0.75993896, dtype=float32), array(-0.7602419, dtype=float32), array(-0.7605154, dtype=float32), array(-0.76090825, dtype=float32), array(-0.76110154, dtype=float32), array(-0.7614845, dtype=float32), array(-0.7617385, dtype=float32), array(-0.7620319, dtype=float32), array(-0.7624093, dtype=float32), array(-0.7626004, dtype=float32), array(-0.7630029, dtype=float32), array(-0.76320547, dtype=float32), array(-0.7634911, dtype=float32), array(-0.7638916, dtype=float32), array(-0.76402134, dtype=float32), array(-0.7644064, dtype=float32), array(-0.76463395, dtype=float32), array(-0.764779, dtype=float32), array(-0.76525235, dtype=float32), array(-0.7652259, dtype=float32), array(-0.76523554, dtype=float32), array(-0.76554394, dtype=float32), array(-0.7660456, dtype=float32), array(-0.7659315, dtype=float32), array(-0.766009, dtype=float32), array(-0.7663223, dtype=float32), array(-0.76683825, dtype=float32), array(-0.7672012, dtype=float32), array(-0.76738703, dtype=float32), array(-0.76777095, dtype=float32), array(-0.7682893, dtype=float32), array(-0.7685679, dtype=float32), array(-0.7686223, dtype=float32), array(-0.7688532, dtype=float32), array(-0.7692065, dtype=float32), array(-0.7696592, dtype=float32), array(-0.7698485, dtype=float32), array(-0.7700678, dtype=float32), array(-0.770504, dtype=float32), array(-0.77104795, dtype=float32), array(-0.77128327, dtype=float32), array(-0.7715347, dtype=float32), array(-0.77189034, dtype=float32), array(-0.7723176, dtype=float32), array(-0.7727036, dtype=float32), array(-0.7728301, dtype=float32), array(-0.77310115, dtype=float32), array(-0.77351296, dtype=float32), array(-0.7740065, dtype=float32), array(-0.77415264, dtype=float32), array(-0.7742731, dtype=float32), array(-0.7745838, dtype=float32), array(-0.77498406, dtype=float32), array(-0.7754054, dtype=float32), array(-0.775532, dtype=float32), array(-0.77575153, dtype=float32), array(-0.7761304, dtype=float32), array(-0.776591, dtype=float32), array(-0.77697396, dtype=float32), array(-0.7770025, dtype=float32), array(-0.77722895, dtype=float32), array(-0.7775819, dtype=float32), array(-0.77799857, dtype=float32), array(-0.778377, dtype=float32), array(-0.77848023, dtype=float32), array(-0.77871084, dtype=float32), array(-0.77910167, dtype=float32), array(-0.77958214, dtype=float32), array(-0.7800524, dtype=float32), array(-0.7802178, dtype=float32), array(-0.78044105, dtype=float32), array(-0.7808017, dtype=float32), array(-0.7812196, dtype=float32), array(-0.7816424, dtype=float32), array(-0.78181815, dtype=float32), array(-0.7820034, dtype=float32), array(-0.782304, dtype=float32), array(-0.78266877, dtype=float32), array(-0.7830547, dtype=float32), array(-0.7831661, dtype=float32), array(-0.7833245, dtype=float32), array(-0.7836582, dtype=float32), array(-0.78406835, dtype=float32), array(-0.7844674, dtype=float32), array(-0.7845848, dtype=float32), array(-0.78481555, dtype=float32), array(-0.78516316, dtype=float32), array(-0.78556883, dtype=float32), array(-0.7859771, dtype=float32), array(-0.7861574, dtype=float32), array(-0.78639954, dtype=float32), array(-0.7867567, dtype=float32), array(-0.7871754, dtype=float32), array(-0.7875913, dtype=float32), array(-0.7877721, dtype=float32), array(-0.7879671, dtype=float32), array(-0.78829277, dtype=float32), array(-0.7886807, dtype=float32), array(-0.7890978, dtype=float32), array(-0.7893364, dtype=float32), array(-0.78952825, dtype=float32), array(-0.78984433, dtype=float32), array(-0.7902302, dtype=float32), array(-0.7906439, dtype=float32), array(-0.7908778, dtype=float32), array(-0.7910282, dtype=float32), array(-0.7913321, dtype=float32), array(-0.7917253, dtype=float32), array(-0.7921378, dtype=float32), array(-0.7924518, dtype=float32), array(-0.7925989, dtype=float32), array(-0.79287356, dtype=float32), array(-0.7932534, dtype=float32), array(-0.79366446, dtype=float32), array(-0.7940176, dtype=float32), array(-0.7941551, dtype=float32), array(-0.7944066, dtype=float32), array(-0.7947896, dtype=float32), array(-0.795214, dtype=float32), array(-0.7956287, dtype=float32), array(-0.7958336, dtype=float32), array(-0.79605055, dtype=float32), array(-0.7964074, dtype=float32), array(-0.79683983, dtype=float32), array(-0.7972757, dtype=float32), array(-0.7975559, dtype=float32), array(-0.7977334, dtype=float32), array(-0.79803556, dtype=float32), array(-0.79843795, dtype=float32), array(-0.79886377, dtype=float32), array(-0.7992723, dtype=float32), array(-0.7995162, dtype=float32), array(-0.799781, dtype=float32), array(-0.8001553, dtype=float32), array(-0.80058444, dtype=float32), array(-0.8010082, dtype=float32), array(-0.8013102, dtype=float32), array(-0.8015076, dtype=float32), array(-0.8018082, dtype=float32), array(-0.80220854, dtype=float32), array(-0.802623, dtype=float32), array(-0.803014, dtype=float32), array(-0.8032555, dtype=float32), array(-0.8035054, dtype=float32), array(-0.80386657, dtype=float32), array(-0.80429393, dtype=float32), array(-0.80472225, dtype=float32), array(-0.8050486, dtype=float32), array(-0.80529845, dtype=float32), array(-0.8056366, dtype=float32), array(-0.8060517, dtype=float32), array(-0.80648595, dtype=float32), array(-0.8068971, dtype=float32), array(-0.8071665, dtype=float32), array(-0.80743104, dtype=float32), array(-0.8077976, dtype=float32), array(-0.8082309, dtype=float32), array(-0.8086559, dtype=float32), array(-0.8090024, dtype=float32), array(-0.80923635, dtype=float32), array(-0.80953807, dtype=float32), array(-0.8099333, dtype=float32), array(-0.8103623, dtype=float32), array(-0.81076604, dtype=float32), array(-0.81106275, dtype=float32), array(-0.81133157, dtype=float32), array(-0.8116892, dtype=float32), array(-0.8121039, dtype=float32), array(-0.8125132, dtype=float32), array(-0.8128792, dtype=float32), array(-0.81314814, dtype=float32), array(-0.8134513, dtype=float32), array(-0.813842, dtype=float32), array(-0.8142562, dtype=float32), array(-0.8146553, dtype=float32), array(-0.81499064, dtype=float32), array(-0.81528074, dtype=float32), array(-0.8156336, dtype=float32), array(-0.8160387, dtype=float32), array(-0.81643546, dtype=float32), array(-0.81680375, dtype=float32), array(-0.8171012, dtype=float32), array(-0.8174208, dtype=float32), array(-0.8178086, dtype=float32), array(-0.8182131, dtype=float32), array(-0.81860125, dtype=float32), array(-0.8189403, dtype=float32), array(-0.81924963, dtype=float32), array(-0.8196152, dtype=float32), array(-0.82001746, dtype=float32), array(-0.82041436, dtype=float32), array(-0.8207781, dtype=float32), array(-0.8210816, dtype=float32), array(-0.8214184, dtype=float32), array(-0.82180065, dtype=float32), array(-0.822192, dtype=float32), array(-0.8225687, dtype=float32), array(-0.82289743, dtype=float32), array(-0.8232285, dtype=float32), array(-0.8236076, dtype=float32), array(-0.8240064, dtype=float32), array(-0.82439184, dtype=float32), array(-0.82472247, dtype=float32), array(-0.8250436, dtype=float32), array(-0.8254246, dtype=float32), array(-0.82581675, dtype=float32), array(-0.82619745, dtype=float32), array(-0.8265362, dtype=float32), array(-0.8268577, dtype=float32), array(-0.82723063, dtype=float32), array(-0.82762545, dtype=float32), array(-0.82801074, dtype=float32), array(-0.82835466, dtype=float32), array(-0.8286781, dtype=float32), array(-0.82905215, dtype=float32), array(-0.8294431, dtype=float32), array(-0.8298256, dtype=float32), array(-0.83018416, dtype=float32), array(-0.83052045, dtype=float32), array(-0.8308962, dtype=float32), array(-0.83129436, dtype=float32), array(-0.83168155, dtype=float32), array(-0.8320392, dtype=float32), array(-0.832375, dtype=float32), array(-0.8327509, dtype=float32), array(-0.8331461, dtype=float32), array(-0.833527, dtype=float32), array(-0.83388466, dtype=float32), array(-0.83421916, dtype=float32), array(-0.83459187, dtype=float32), array(-0.8349946, dtype=float32), array(-0.8353817, dtype=float32), array(-0.8357372, dtype=float32), array(-0.8360796, dtype=float32), array(-0.83646077, dtype=float32), array(-0.8368581, dtype=float32), array(-0.83723587, dtype=float32), array(-0.83759516, dtype=float32), array(-0.83794785, dtype=float32), array(-0.8383307, dtype=float32), array(-0.8387171, dtype=float32), array(-0.839094, dtype=float32), array(-0.83944684, dtype=float32), array(-0.83980936, dtype=float32), array(-0.84020656, dtype=float32), array(-0.84059, dtype=float32), array(-0.8409668, dtype=float32), array(-0.841323, dtype=float32), array(-0.8416912, dtype=float32), array(-0.842086, dtype=float32), array(-0.8424681, dtype=float32), array(-0.84284097, dtype=float32), array(-0.8431965, dtype=float32), array(-0.8435783, dtype=float32), array(-0.84397, dtype=float32), array(-0.8443493, dtype=float32), array(-0.8447138, dtype=float32), array(-0.84508115, dtype=float32), array(-0.84546643, dtype=float32), array(-0.8458403, dtype=float32), array(-0.8462109, dtype=float32), array(-0.8465616, dtype=float32), array(-0.8469376, dtype=float32)], 'val_D': [array(-4.017353e-05, dtype=float32), array(-0.00015563, dtype=float32), array(-0.0002448, dtype=float32), array(-0.00030428, dtype=float32), array(-0.00023204, dtype=float32), array(1.2934208e-05, dtype=float32), array(0.00062078, dtype=float32), array(0.00187725, dtype=float32), array(0.00385863, dtype=float32), array(0.00588435, dtype=float32), array(0.00699562, dtype=float32), array(0.00713682, dtype=float32), array(0.00686324, dtype=float32), array(0.00645506, dtype=float32), array(0.00603271, dtype=float32), array(0.00562692, dtype=float32), array(0.0052411, dtype=float32), array(0.00488377, dtype=float32), array(0.00455952, dtype=float32), array(0.00426751, dtype=float32), array(0.00400704, dtype=float32), array(0.00376475, dtype=float32), array(0.00353181, dtype=float32), array(0.00333822, dtype=float32), array(0.00316834, dtype=float32), array(0.0030275, dtype=float32), array(0.00290197, dtype=float32), array(0.00276673, dtype=float32), array(0.00263983, dtype=float32), array(0.00252718, dtype=float32), array(0.00243676, dtype=float32), array(0.00235945, dtype=float32), array(0.0023095, dtype=float32), array(0.00227541, dtype=float32), array(0.00225604, dtype=float32), array(0.00224268, dtype=float32), array(0.00222278, dtype=float32), array(0.00219381, dtype=float32), array(0.0021655, dtype=float32), array(0.00214434, dtype=float32), array(0.002123, dtype=float32), array(0.0020926, dtype=float32), array(0.00204682, dtype=float32), array(0.00201279, dtype=float32), array(0.00199705, dtype=float32), array(0.00198162, dtype=float32), array(0.00196671, dtype=float32), array(0.00194681, dtype=float32), array(0.00192195, dtype=float32), array(0.00189304, dtype=float32), array(0.00183868, dtype=float32), array(0.00181299, dtype=float32), array(0.0017938, dtype=float32), array(0.00176704, dtype=float32), array(0.00172907, dtype=float32), array(0.00170231, dtype=float32), array(0.00169063, dtype=float32), array(0.00167507, dtype=float32), array(0.00166106, dtype=float32), array(0.00165254, dtype=float32), array(0.00164163, dtype=float32), array(0.00162345, dtype=float32), array(0.00158709, dtype=float32), array(0.00154781, dtype=float32), array(0.0015232, dtype=float32), array(0.00150782, dtype=float32), array(0.00149411, dtype=float32), array(0.00148398, dtype=float32), array(0.00147372, dtype=float32), array(0.00146437, dtype=float32), array(0.00144976, dtype=float32), array(0.00143397, dtype=float32), array(0.00141585, dtype=float32), array(0.00139654, dtype=float32), array(0.00135911, dtype=float32), array(0.00130868, dtype=float32), array(0.00127554, dtype=float32), array(0.00125694, dtype=float32), array(0.00124872, dtype=float32), array(0.0012393, dtype=float32), array(0.00122541, dtype=float32), array(0.00121498, dtype=float32), array(0.00120425, dtype=float32), array(0.00119162, dtype=float32), array(0.00116974, dtype=float32), array(0.00113845, dtype=float32), array(0.0011279, dtype=float32), array(0.00112259, dtype=float32), array(0.0011186, dtype=float32), array(0.00111264, dtype=float32), array(0.00110555, dtype=float32), array(0.00109625, dtype=float32), array(0.00108498, dtype=float32), array(0.0010708, dtype=float32), array(0.00105566, dtype=float32), array(0.00103992, dtype=float32), array(0.00102723, dtype=float32), array(0.00101411, dtype=float32), array(0.00099987, dtype=float32), array(0.00098819, dtype=float32), array(0.00097257, dtype=float32), array(0.00095856, dtype=float32), array(0.00094843, dtype=float32), array(0.0009349, dtype=float32), array(0.00092137, dtype=float32), array(0.00090873, dtype=float32), array(0.00089926, dtype=float32), array(0.00089085, dtype=float32), array(0.00087881, dtype=float32), array(0.00086892, dtype=float32), array(0.0008595, dtype=float32), array(0.0008477, dtype=float32), array(0.00083619, dtype=float32), array(0.00082439, dtype=float32), array(0.00081468, dtype=float32), array(0.00080526, dtype=float32), array(0.00079548, dtype=float32), array(0.00078607, dtype=float32), array(0.00077802, dtype=float32), array(0.00076497, dtype=float32), array(0.00075549, dtype=float32), array(0.00074869, dtype=float32), array(0.00074011, dtype=float32), array(0.00073344, dtype=float32), array(0.00072521, dtype=float32), array(0.00071913, dtype=float32), array(0.00071251, dtype=float32), array(0.00071001, dtype=float32), array(0.00070709, dtype=float32), array(0.00070041, dtype=float32), array(0.00069553, dtype=float32), array(0.00068724, dtype=float32), array(0.00068015, dtype=float32), array(0.00067329, dtype=float32), array(0.00066155, dtype=float32), array(0.00063467, dtype=float32), array(0.00062001, dtype=float32), array(0.00061721, dtype=float32), array(0.00061524, dtype=float32), array(0.00061148, dtype=float32), array(0.00060391, dtype=float32), array(0.00059879, dtype=float32), array(0.00059307, dtype=float32), array(0.0005886, dtype=float32), array(0.00058341, dtype=float32), array(0.00057948, dtype=float32), array(0.00057328, dtype=float32), array(0.00056654, dtype=float32), array(0.00056124, dtype=float32), array(0.00055432, dtype=float32), array(0.00055069, dtype=float32), array(0.0005455, dtype=float32), array(0.00053751, dtype=float32), array(0.00053102, dtype=float32), array(0.00052071, dtype=float32), array(0.00051129, dtype=float32), array(0.00050849, dtype=float32), array(0.00050384, dtype=float32), array(0.00049895, dtype=float32), array(0.00049365, dtype=float32), array(0.00048965, dtype=float32), array(0.00048316, dtype=float32), array(0.00047404, dtype=float32), array(0.00047082, dtype=float32), array(0.00046849, dtype=float32), array(0.00046402, dtype=float32), array(0.00045788, dtype=float32), array(0.00044847, dtype=float32), array(0.00043797, dtype=float32), array(0.00043482, dtype=float32), array(0.00042707, dtype=float32), array(0.00042737, dtype=float32), array(0.00042623, dtype=float32), array(0.00042111, dtype=float32), array(0.00041497, dtype=float32), array(0.0004099, dtype=float32), array(0.00040311, dtype=float32), array(0.00040847, dtype=float32), array(0.00040215, dtype=float32), array(0.00039393, dtype=float32), array(0.00038385, dtype=float32), array(0.00037837, dtype=float32), array(0.00037384, dtype=float32), array(0.00036979, dtype=float32), array(0.00036639, dtype=float32), array(0.00036162, dtype=float32), array(0.00035548, dtype=float32), array(0.00035286, dtype=float32), array(0.00035113, dtype=float32), array(0.00035131, dtype=float32), array(0.00035077, dtype=float32), array(0.00034666, dtype=float32), array(0.00034577, dtype=float32), array(0.00034046, dtype=float32), array(0.00033104, dtype=float32), array(0.00032949, dtype=float32), array(0.00032145, dtype=float32), array(0.0003137, dtype=float32), array(0.00031072, dtype=float32), array(0.00030613, dtype=float32), array(0.00030124, dtype=float32), array(0.00030422, dtype=float32), array(0.00030637, dtype=float32), array(0.00030273, dtype=float32), array(0.00030297, dtype=float32), array(0.00030273, dtype=float32), array(0.00028652, dtype=float32), array(0.00028116, dtype=float32), array(0.00028193, dtype=float32), array(0.00028384, dtype=float32), array(0.0002833, dtype=float32), array(0.00027663, dtype=float32), array(0.00027382, dtype=float32), array(0.00027227, dtype=float32), array(0.00026822, dtype=float32), array(0.00026715, dtype=float32), array(0.00026315, dtype=float32), array(0.0002625, dtype=float32), array(0.00025988, dtype=float32), array(0.00025743, dtype=float32), array(0.00025433, dtype=float32), array(0.00025165, dtype=float32), array(0.00024527, dtype=float32), array(0.00024551, dtype=float32), array(0.00024426, dtype=float32), array(0.00023621, dtype=float32), array(0.00023186, dtype=float32), array(0.00023174, dtype=float32), array(0.00022852, dtype=float32), array(0.00022429, dtype=float32), array(0.00022042, dtype=float32), array(0.00021768, dtype=float32), array(0.00021607, dtype=float32), array(0.00021344, dtype=float32), array(0.00021362, dtype=float32), array(0.00020701, dtype=float32), array(0.00020146, dtype=float32), array(0.00020212, dtype=float32), array(0.0001992, dtype=float32), array(0.00019693, dtype=float32), array(0.00020081, dtype=float32), array(0.0001986, dtype=float32), array(0.00019389, dtype=float32), array(0.00018835, dtype=float32), array(0.00018448, dtype=float32), array(0.00017929, dtype=float32), array(0.00017542, dtype=float32), array(0.00017375, dtype=float32), array(0.00017518, dtype=float32), array(0.00017118, dtype=float32), array(0.00016922, dtype=float32), array(0.00016165, dtype=float32), array(0.00016195, dtype=float32), array(0.00015968, dtype=float32), array(0.00015587, dtype=float32), array(0.00015104, dtype=float32), array(0.00014889, dtype=float32), array(0.00014651, dtype=float32), array(0.00014424, dtype=float32), array(0.00013983, dtype=float32), array(0.00014114, dtype=float32), array(0.00013345, dtype=float32), array(0.00012916, dtype=float32), array(0.00012857, dtype=float32), array(0.00012451, dtype=float32), array(0.00012261, dtype=float32), array(0.00011665, dtype=float32), array(0.0001151, dtype=float32), array(0.00011015, dtype=float32), array(0.0001058, dtype=float32), array(0.00010443, dtype=float32), array(0.00010121, dtype=float32), array(9.649992e-05, dtype=float32), array(9.196997e-05, dtype=float32), array(8.6307526e-05, dtype=float32), array(8.4877014e-05, dtype=float32), array(7.8082085e-05, dtype=float32), array(7.5519085e-05, dtype=float32), array(7.44462e-05, dtype=float32), array(6.753206e-05, dtype=float32), array(5.9068203e-05, dtype=float32), array(5.531311e-05, dtype=float32), array(5.1259995e-05, dtype=float32), array(5.0663948e-05, dtype=float32), array(3.8325787e-05, dtype=float32), array(3.8683414e-05, dtype=float32), array(2.9146671e-05, dtype=float32), array(3.2246113e-05, dtype=float32), array(2.0623207e-05, dtype=float32), array(9.357929e-06, dtype=float32), array(5.066395e-06, dtype=float32), array(3.1590462e-06, dtype=float32), array(2.4437904e-06, dtype=float32), array(-1.3589859e-05, dtype=float32), array(-1.5974045e-05, dtype=float32), array(-2.3424625e-05, dtype=float32), array(-3.2901764e-05, dtype=float32), array(-3.7014484e-05, dtype=float32), array(-3.7431717e-05, dtype=float32), array(-5.4240227e-05, dtype=float32), array(-6.2167645e-05, dtype=float32), array(-6.520748e-05, dtype=float32), array(-7.587671e-05, dtype=float32), array(-7.7843666e-05, dtype=float32), array(-8.98242e-05, dtype=float32), array(-0.00010365, dtype=float32), array(-0.00010693, dtype=float32), array(-0.00010943, dtype=float32), array(-0.00012171, dtype=float32), array(-0.0001269, dtype=float32), array(-0.00013864, dtype=float32), array(-0.00013793, dtype=float32), array(-0.00014043, dtype=float32), array(-0.00014573, dtype=float32), array(-0.00015539, dtype=float32), array(-0.00014967, dtype=float32), array(-0.00015187, dtype=float32), array(-0.00015599, dtype=float32), array(-0.00014567, dtype=float32), array(-0.0001381, dtype=float32), array(-0.0001353, dtype=float32), array(-0.00012767, dtype=float32), array(-0.00011814, dtype=float32), array(-9.4652176e-05, dtype=float32), array(-9.3340874e-05, dtype=float32), array(-8.2850456e-05, dtype=float32), array(-7.349253e-05, dtype=float32), array(-5.3584576e-05, dtype=float32), array(-2.2411346e-05, dtype=float32), array(-4.094839e-05, dtype=float32), array(-1.1563301e-05, dtype=float32), array(2.4557114e-05, dtype=float32), array(-6.0796738e-06, dtype=float32), array(5.030632e-05, dtype=float32), array(0.000117, dtype=float32), array(-0.00011712, dtype=float32), array(0.00037998, dtype=float32), array(0.00041473, dtype=float32), array(0.00036174, dtype=float32), array(0.00065958, dtype=float32), array(0.00198442, dtype=float32), array(-6.2823296e-05, dtype=float32), array(-7.2062016e-05, dtype=float32), array(0.00161725, dtype=float32), array(-0.00013208, dtype=float32), array(0.00028712, dtype=float32), array(0.00037742, dtype=float32), array(6.622076e-05, dtype=float32), array(8.273125e-05, dtype=float32), array(0.00035584, dtype=float32), array(8.791685e-05, dtype=float32), array(8.106232e-05, dtype=float32), array(0.00027221, dtype=float32), array(0.00018883, dtype=float32), array(8.2850456e-05, dtype=float32), array(0.00024909, dtype=float32), array(0.00017071, dtype=float32), array(5.143881e-05, dtype=float32), array(0.0002405, dtype=float32), array(0.00018221, dtype=float32), array(5.197525e-05, dtype=float32), array(0.00033462, dtype=float32), array(0.00014526, dtype=float32), array(0.00012922, dtype=float32), array(0.00025856, dtype=float32), array(0.00015861, dtype=float32), array(5.632639e-05, dtype=float32), array(0.00040078, dtype=float32), array(6.580353e-05, dtype=float32), array(0.00019681, dtype=float32), array(0.00024587, dtype=float32), array(0.00013679, dtype=float32), array(6.502867e-05, dtype=float32), array(0.00034368, dtype=float32), array(7.212162e-05, dtype=float32), array(0.00018656, dtype=float32), array(0.00021613, dtype=float32), array(0.00012082, dtype=float32), array(7.843971e-05, dtype=float32), array(0.00030714, dtype=float32), array(6.8724155e-05, dtype=float32), array(0.00017816, dtype=float32), array(0.00020784, dtype=float32), array(0.00012076, dtype=float32), array(9.864569e-05, dtype=float32), array(0.00025147, dtype=float32), array(7.086992e-05, dtype=float32), array(0.00017583, dtype=float32), array(0.00017625, dtype=float32), array(9.7990036e-05, dtype=float32), array(0.0001474, dtype=float32), array(0.0001756, dtype=float32), array(8.636713e-05, dtype=float32), array(0.00016862, dtype=float32), array(0.00011992, dtype=float32), array(8.767843e-05, dtype=float32), array(0.00018984, dtype=float32), array(6.67572e-05, dtype=float32), array(0.00016183, dtype=float32), array(0.0001179, dtype=float32), array(9.7215176e-05, dtype=float32), array(0.00015396, dtype=float32), array(8.970499e-05, dtype=float32), array(0.00015378, dtype=float32), array(9.214878e-05, dtype=float32), array(0.00017363, dtype=float32), array(0.00010085, dtype=float32), array(0.00013179, dtype=float32), array(0.000135, dtype=float32), array(7.379055e-05, dtype=float32), array(0.00017291, dtype=float32), array(6.330013e-05, dtype=float32), array(0.00014007, dtype=float32), array(9.584427e-05, dtype=float32), array(0.00015724, dtype=float32), array(0.00010258, dtype=float32), array(0.00013685, dtype=float32), array(0.00013101, dtype=float32), array(6.2286854e-05, dtype=float32), array(0.00019574, dtype=float32), array(5.1259995e-05, dtype=float32), array(0.00015837, dtype=float32), array(0.00011396, dtype=float32), array(7.838011e-05, dtype=float32), array(0.00016761, dtype=float32), array(6.812811e-05, dtype=float32), array(0.0001561, dtype=float32), array(9.971857e-05, dtype=float32), array(0.00012261, dtype=float32), array(0.00015759, dtype=float32), array(8.779764e-05, dtype=float32), array(0.00016618, dtype=float32), array(0.00010747, dtype=float32), array(9.8347664e-05, dtype=float32), array(0.00015837, dtype=float32), array(6.610155e-05, dtype=float32), array(0.00017166, dtype=float32), array(0.00012022, dtype=float32), array(8.428097e-05, dtype=float32), array(0.00019872, dtype=float32), array(5.275011e-05, dtype=float32), array(0.00016928, dtype=float32), array(0.00014603, dtype=float32), array(8.624792e-05, dtype=float32), array(0.00018084, dtype=float32), array(0.00010765, dtype=float32), array(0.00011486, dtype=float32), array(0.0001533, dtype=float32), array(9.781122e-05, dtype=float32), array(0.00012171, dtype=float32), array(0.00014991, dtype=float32), array(6.765127e-05, dtype=float32), array(0.00014836, dtype=float32), array(0.00010198, dtype=float32), array(7.56979e-05, dtype=float32), array(0.00018746, dtype=float32), array(4.631281e-05, dtype=float32), array(0.0001533, dtype=float32), array(0.00011897, dtype=float32), array(6.151199e-05, dtype=float32), array(0.00019741, dtype=float32), array(8.6545944e-05, dtype=float32), array(0.00012356, dtype=float32), array(0.00014055, dtype=float32), array(0.00010085, dtype=float32), array(0.00010395, dtype=float32), array(0.00013739, dtype=float32), array(7.8976154e-05, dtype=float32), array(0.00012457, dtype=float32), array(0.00012577, dtype=float32), array(5.477667e-05, dtype=float32), array(0.00018734, dtype=float32), array(7.712841e-05, dtype=float32), array(0.000126, dtype=float32), array(0.00018281, dtype=float32), array(5.042553e-05, dtype=float32), array(0.00015801, dtype=float32), array(0.00016689, dtype=float32), array(6.610155e-05, dtype=float32), array(0.00015533, dtype=float32), array(0.00013208, dtype=float32), array(0.00010085, dtype=float32), array(7.534027e-05, dtype=float32), array(0.00015801, dtype=float32), array(6.735325e-05, dtype=float32), array(0.00011361, dtype=float32), array(9.983778e-05, dtype=float32), array(9.638071e-05, dtype=float32), array(9.62019e-05, dtype=float32), array(0.00012106, dtype=float32), array(8.457899e-05, dtype=float32), array(9.161234e-05, dtype=float32), array(0.00012594, dtype=float32), array(4.786253e-05, dtype=float32), array(0.0001452, dtype=float32), array(9.8347664e-05, dtype=float32), array(8.302927e-05, dtype=float32), array(0.00012869, dtype=float32), array(9.36389e-05, dtype=float32), array(7.468462e-05, dtype=float32), array(0.00013542, dtype=float32), array(8.7082386e-05, dtype=float32), array(8.702278e-05, dtype=float32), array(0.00010508, dtype=float32), array(7.5399876e-05, dtype=float32), array(9.7215176e-05, dtype=float32), array(0.00010914, dtype=float32), array(8.0406666e-05, dtype=float32), array(9.453297e-05, dtype=float32), array(0.0001089, dtype=float32), array(6.9499016e-05, dtype=float32), array(0.00011384, dtype=float32), array(9.11355e-05, dtype=float32), array(9.083748e-05, dtype=float32), array(9.936094e-05, dtype=float32), array(9.1314316e-05, dtype=float32), array(7.724762e-05, dtype=float32), array(0.00010592, dtype=float32), array(7.2062016e-05, dtype=float32), array(8.529425e-05, dtype=float32), array(8.1419945e-05, dtype=float32), array(7.0273876e-05, dtype=float32), array(9.202957e-05, dtype=float32), array(7.367134e-05, dtype=float32), array(7.69496e-05, dtype=float32), array(8.422136e-05, dtype=float32), array(6.622076e-05, dtype=float32), array(8.85725e-05, dtype=float32), array(7.2062016e-05, dtype=float32), array(7.6532364e-05, dtype=float32), array(7.772446e-05, dtype=float32), array(6.645918e-05, dtype=float32), array(8.8870525e-05, dtype=float32), array(6.8724155e-05, dtype=float32), array(8.08239e-05, dtype=float32), array(7.4744225e-05, dtype=float32), array(6.365776e-05, dtype=float32), array(8.493662e-05, dtype=float32), array(6.109476e-05, dtype=float32), array(8.016825e-05, dtype=float32), array(6.5624714e-05, dtype=float32), array(8.362532e-05, dtype=float32), array(7.122755e-05, dtype=float32), array(7.176399e-05, dtype=float32), array(7.605553e-05, dtype=float32), array(6.0379505e-05, dtype=float32), array(8.72612e-05, dtype=float32), array(6.0141087e-05, dtype=float32), array(7.933378e-05, dtype=float32), array(6.67572e-05, dtype=float32), array(6.848574e-05, dtype=float32), array(7.855892e-05, dtype=float32), array(6.198883e-05, dtype=float32), array(7.8976154e-05, dtype=float32), array(5.8352947e-05, dtype=float32), array(8.547306e-05, dtype=float32), array(5.9604645e-05, dtype=float32), array(8.106232e-05, dtype=float32), array(6.514788e-05, dtype=float32), array(6.866455e-05, dtype=float32), array(7.3075294e-05, dtype=float32), array(6.735325e-05, dtype=float32), array(7.480383e-05, dtype=float32), array(5.7399273e-05, dtype=float32), array(8.535385e-05, dtype=float32), array(5.6385994e-05, dtype=float32), array(7.992983e-05, dtype=float32), array(6.133318e-05, dtype=float32), array(7.992983e-05, dtype=float32), array(6.651878e-05, dtype=float32), array(7.2062016e-05, dtype=float32), array(7.2062016e-05, dtype=float32), array(5.6505203e-05, dtype=float32), array(7.9870224e-05, dtype=float32), array(5.4597855e-05, dtype=float32), array(8.112192e-05, dtype=float32), array(5.3942204e-05, dtype=float32), array(8.529425e-05, dtype=float32), array(6.0617924e-05, dtype=float32), array(7.766485e-05, dtype=float32), array(6.759167e-05, dtype=float32), array(5.6028366e-05, dtype=float32), array(7.933378e-05, dtype=float32), array(5.3048134e-05, dtype=float32), array(7.492304e-05, dtype=float32), array(5.2928925e-05, dtype=float32), array(8.136034e-05, dtype=float32), array(5.5789948e-05, dtype=float32), array(7.253885e-05, dtype=float32), array(6.335974e-05, dtype=float32), array(6.2286854e-05, dtype=float32), array(6.771088e-05, dtype=float32), array(5.7399273e-05, dtype=float32), array(7.021427e-05, dtype=float32), array(5.0365925e-05, dtype=float32), array(7.456541e-05, dtype=float32), array(5.0604343e-05, dtype=float32), array(7.1406364e-05, dtype=float32), array(5.5253506e-05, dtype=float32), array(6.80089e-05, dtype=float32), array(5.9187412e-05, dtype=float32), array(6.300211e-05, dtype=float32), array(6.3717365e-05, dtype=float32), array(5.209446e-05, dtype=float32), array(6.67572e-05, dtype=float32), array(4.9948692e-05, dtype=float32), array(6.788969e-05, dtype=float32), array(4.941225e-05, dtype=float32), array(6.8962574e-05, dtype=float32), array(4.9710274e-05, dtype=float32), array(6.610155e-05, dtype=float32), array(5.275011e-05, dtype=float32), array(6.240606e-05, dtype=float32), array(5.4061413e-05, dtype=float32), array(6.1154366e-05, dtype=float32), array(5.555153e-05, dtype=float32), array(5.340576e-05, dtype=float32), array(5.877018e-05, dtype=float32), array(5.4359436e-05, dtype=float32), array(5.7697296e-05, dtype=float32), array(4.976988e-05, dtype=float32), array(6.1392784e-05, dtype=float32), array(4.863739e-05, dtype=float32), array(5.853176e-05, dtype=float32), array(4.8339367e-05, dtype=float32), array(6.198883e-05, dtype=float32), array(4.774332e-05, dtype=float32), array(5.9127808e-05, dtype=float32), array(5.0723553e-05, dtype=float32), array(5.5491924e-05, dtype=float32), array(4.9054623e-05, dtype=float32), array(5.543232e-05, dtype=float32), array(5.1021576e-05, dtype=float32), array(5.0485134e-05, dtype=float32), array(5.2571297e-05, dtype=float32), array(5.1140785e-05, dtype=float32), array(5.26309e-05, dtype=float32), array(4.6908855e-05, dtype=float32), array(5.2928925e-05, dtype=float32), array(4.976988e-05, dtype=float32), array(5.108118e-05, dtype=float32), array(4.5120716e-05, dtype=float32), array(5.2809715e-05, dtype=float32), array(4.6014786e-05, dtype=float32), array(5.0246716e-05, dtype=float32), array(4.4345856e-05, dtype=float32), array(5.209446e-05, dtype=float32), array(4.541874e-05, dtype=float32), array(5.120039e-05, dtype=float32), array(4.416704e-05, dtype=float32), array(5.120039e-05, dtype=float32), array(4.595518e-05, dtype=float32), array(4.7504902e-05, dtype=float32), array(4.351139e-05, dtype=float32), array(4.9352646e-05, dtype=float32), array(4.416704e-05, dtype=float32), array(4.6372414e-05, dtype=float32), array(4.452467e-05, dtype=float32), array(4.5597553e-05, dtype=float32), array(4.4047832e-05, dtype=float32), array(4.643202e-05, dtype=float32), array(4.3809414e-05, dtype=float32), array(4.4345856e-05, dtype=float32), array(4.6610832e-05, dtype=float32), array(4.1484833e-05, dtype=float32), array(4.4345856e-05, dtype=float32), array(4.3094158e-05, dtype=float32), array(4.4107437e-05, dtype=float32), array(4.1127205e-05, dtype=float32), array(4.529953e-05, dtype=float32), array(3.951788e-05, dtype=float32), array(4.3928623e-05, dtype=float32), array(3.916025e-05, dtype=float32), array(4.518032e-05, dtype=float32), array(3.8444996e-05, dtype=float32), array(4.3332577e-05, dtype=float32), array(3.8325787e-05, dtype=float32), array(4.3034554e-05, dtype=float32), array(3.9339066e-05, dtype=float32), array(4.0352345e-05, dtype=float32), array(3.916025e-05, dtype=float32), array(4.0352345e-05, dtype=float32), array(3.9875507e-05, dtype=float32), array(3.796816e-05, dtype=float32), array(4.2259693e-05, dtype=float32), array(3.772974e-05, dtype=float32), array(3.9339066e-05, dtype=float32), array(3.838539e-05, dtype=float32), array(4.130602e-05, dtype=float32), array(3.606081e-05, dtype=float32), array(4.1902065e-05, dtype=float32), array(3.6656857e-05, dtype=float32), array(3.951788e-05, dtype=float32), array(3.9100647e-05, dtype=float32), array(3.9994717e-05, dtype=float32), array(3.916025e-05, dtype=float32), array(3.6537647e-05, dtype=float32), array(3.629923e-05, dtype=float32), array(4.0233135e-05, dtype=float32), array(3.7550926e-05, dtype=float32), array(3.6001205e-05, dtype=float32), array(3.749132e-05, dtype=float32), array(3.7431717e-05, dtype=float32), array(4.273653e-05, dtype=float32), array(3.606081e-05, dtype=float32), array(3.6001205e-05, dtype=float32), array(3.3676624e-05, dtype=float32), array(3.5464764e-05, dtype=float32), array(3.9339066e-05, dtype=float32), array(3.4987926e-05, dtype=float32), array(3.4689903e-05, dtype=float32), array(3.373623e-05, dtype=float32), array(3.4570694e-05, dtype=float32), array(3.939867e-05, dtype=float32), array(3.629923e-05, dtype=float32), array(3.4451485e-05, dtype=float32), array(3.159046e-05, dtype=float32), array(3.4213066e-05, dtype=float32), array(3.7431717e-05, dtype=float32), array(3.3676624e-05, dtype=float32), array(3.3795834e-05, dtype=float32), array(3.0577183e-05, dtype=float32), array(3.260374e-05, dtype=float32), array(3.9577484e-05, dtype=float32), array(3.4809113e-05, dtype=float32), array(3.4689903e-05, dtype=float32), array(2.9444695e-05, dtype=float32), array(3.0994415e-05, dtype=float32), array(3.504753e-05, dtype=float32), array(3.451109e-05, dtype=float32), array(3.796816e-05, dtype=float32), array(3.1769276e-05, dtype=float32), array(2.9921532e-05, dtype=float32), array(3.1411648e-05, dtype=float32), array(3.2246113e-05, dtype=float32), array(3.6239624e-05, dtype=float32), array(3.170967e-05, dtype=float32), array(2.9325485e-05, dtype=float32), array(3.093481e-05, dtype=float32), array(3.2365322e-05, dtype=float32), array(3.8981438e-05, dtype=float32), array(3.4213066e-05, dtype=float32), array(2.9921532e-05, dtype=float32), array(2.7894974e-05, dtype=float32), array(3.0755997e-05, dtype=float32), array(3.8444996e-05, dtype=float32), array(3.5643578e-05, dtype=float32), array(3.3080578e-05, dtype=float32), array(2.5451183e-05, dtype=float32), array(3.2544136e-05, dtype=float32), array(4.5001507e-05, dtype=float32), array(4.005432e-05, dtype=float32), array(2.6285648e-05, dtype=float32), array(2.4914742e-05, dtype=float32), array(4.094839e-05, dtype=float32), array(5.5789948e-05, dtype=float32), array(2.861023e-06, dtype=float32), array(8.0764294e-05, dtype=float32), array(3.349781e-05, dtype=float32), array(9.161234e-05, dtype=float32), array(4.7683716e-06, dtype=float32), array(7.7188015e-05, dtype=float32), array(4.464388e-05, dtype=float32), array(4.3690205e-05, dtype=float32), array(4.4465065e-05, dtype=float32), array(4.3034554e-05, dtype=float32), array(4.1484833e-05, dtype=float32), array(3.0040741e-05, dtype=float32), array(4.1782856e-05, dtype=float32), array(6.645918e-05, dtype=float32), array(6.610155e-05, dtype=float32), array(3.6776066e-05, dtype=float32), array(5.555153e-05, dtype=float32), array(2.1219254e-05, dtype=float32), array(5.197525e-05, dtype=float32), array(3.6358833e-05, dtype=float32), array(5.2392483e-05, dtype=float32), array(1.6868114e-05, dtype=float32), array(6.0081482e-05, dtype=float32), array(4.4882298e-05, dtype=float32), array(2.8967857e-05, dtype=float32), array(5.0783157e-05, dtype=float32), array(2.193451e-05, dtype=float32), array(5.0842762e-05, dtype=float32), array(3.015995e-05, dtype=float32), array(5.710125e-05, dtype=float32), array(1.8537045e-05, dtype=float32), array(5.38826e-05, dtype=float32), array(4.5835972e-05, dtype=float32), array(2.3901463e-05, dtype=float32), array(6.312132e-05, dtype=float32), array(1.3411045e-05, dtype=float32), array(4.839897e-05, dtype=float32), array(3.8146973e-05, dtype=float32), array(1.9013882e-05, dtype=float32), array(5.888939e-05, dtype=float32), array(1.835823e-05, dtype=float32), array(5.7041645e-05, dtype=float32), array(3.6478043e-05, dtype=float32), array(2.1874905e-05, dtype=float32), array(5.722046e-05, dtype=float32), array(1.0728836e-05, dtype=float32), array(4.9114227e-05, dtype=float32), array(3.874302e-05, dtype=float32), array(2.2232533e-05, dtype=float32), array(5.4061413e-05, dtype=float32), array(1.937151e-05, dtype=float32), array(4.0113926e-05, dtype=float32), array(3.552437e-05, dtype=float32), array(2.0325184e-05, dtype=float32), array(4.4822693e-05, dtype=float32), array(1.692772e-05, dtype=float32), array(4.1544437e-05, dtype=float32), array(4.005432e-05, dtype=float32), array(2.1159649e-05, dtype=float32), array(4.929304e-05, dtype=float32), array(1.2636185e-05, dtype=float32), array(4.3690205e-05, dtype=float32), array(3.5643578e-05, dtype=float32), array(1.5854836e-05, dtype=float32), array(5.7935715e-05, dtype=float32), array(6.556511e-06, dtype=float32), array(4.7028065e-05, dtype=float32), array(3.6537647e-05, dtype=float32), array(1.8239021e-05, dtype=float32), array(5.3226948e-05, dtype=float32), array(1.2218952e-05, dtype=float32), array(4.2676926e-05, dtype=float32), array(3.4749508e-05, dtype=float32), array(1.7762184e-05, dtype=float32), array(4.9710274e-05, dtype=float32), array(1.4305115e-05, dtype=float32), array(3.9339066e-05, dtype=float32), array(3.761053e-05, dtype=float32), array(1.9609928e-05, dtype=float32), array(4.4822693e-05, dtype=float32), array(2.2172928e-05, dtype=float32), array(3.2544136e-05, dtype=float32), array(3.8266182e-05, dtype=float32), array(1.92523e-05, dtype=float32), array(4.249811e-05, dtype=float32), array(2.6285648e-05, dtype=float32), array(2.861023e-05, dtype=float32), array(3.9577484e-05, dtype=float32), array(2.4199486e-05, dtype=float32), array(2.169609e-05, dtype=float32), array(3.8206577e-05, dtype=float32), array(1.2755394e-05, dtype=float32), array(3.7670135e-05, dtype=float32), array(2.5212765e-05, dtype=float32), array(1.4781952e-05, dtype=float32), array(4.452467e-05, dtype=float32), array(7.4505806e-06, dtype=float32), array(3.8206577e-05, dtype=float32), array(3.0517578e-05, dtype=float32), array(1.3232231e-05, dtype=float32), array(4.720688e-05, dtype=float32), array(1.2457371e-05, dtype=float32), array(3.3557415e-05, dtype=float32), array(3.3438206e-05, dtype=float32), array(1.7344952e-05, dtype=float32), array(3.6120415e-05, dtype=float32), array(2.7358532e-05, dtype=float32), array(1.937151e-05, dtype=float32), array(3.71933e-05, dtype=float32), array(2.5629997e-05, dtype=float32), array(1.2099743e-05, dtype=float32), array(4.541874e-05, dtype=float32), array(1.1146069e-05, dtype=float32), array(3.2424927e-05, dtype=float32), array(3.194809e-05, dtype=float32), array(1.6510487e-05, dtype=float32), array(3.2007694e-05, dtype=float32), array(2.8252602e-05, dtype=float32), array(1.31726265e-05, dtype=float32), array(3.4928322e-05, dtype=float32), array(2.4795532e-05, dtype=float32), array(1.1444092e-05, dtype=float32), array(4.0769577e-05, dtype=float32), array(1.168251e-05, dtype=float32), array(2.8669834e-05, dtype=float32), array(2.9563904e-05, dtype=float32), array(1.4603138e-05, dtype=float32), array(3.2424927e-05, dtype=float32), array(2.670288e-05, dtype=float32), array(1.424551e-05, dtype=float32), array(3.0696392e-05, dtype=float32), array(2.4139881e-05, dtype=float32), array(1.0788441e-05, dtype=float32), array(4.017353e-05, dtype=float32), array(1.2218952e-05, dtype=float32), array(2.6345253e-05, dtype=float32), array(2.9325485e-05, dtype=float32), array(1.6272068e-05, dtype=float32), array(2.0384789e-05, dtype=float32), array(3.0994415e-05, dtype=float32), array(7.987022e-06, dtype=float32), array(3.0398369e-05, dtype=float32), array(2.3961067e-05, dtype=float32), array(1.0609627e-05, dtype=float32), array(3.6418438e-05, dtype=float32), array(1.5556812e-05, dtype=float32), array(2.1576881e-05, dtype=float32), array(2.783537e-05, dtype=float32), array(1.7225742e-05, dtype=float32), array(1.3530254e-05, dtype=float32), array(3.2126904e-05, dtype=float32), array(7.3313713e-06, dtype=float32), array(2.515316e-05, dtype=float32), array(2.4199486e-05, dtype=float32), array(1.1980534e-05, dtype=float32), array(3.1471252e-05, dtype=float32), array(1.8894672e-05, dtype=float32), array(1.5437603e-05, dtype=float32), array(2.5391579e-05, dtype=float32), array(1.7166138e-05, dtype=float32), array(1.2040138e-05, dtype=float32), array(2.9921532e-05, dtype=float32), array(8.46386e-06, dtype=float32), array(2.4676323e-05, dtype=float32), array(2.18153e-05, dtype=float32), array(1.1086464e-05, dtype=float32), array(2.95043e-05, dtype=float32), array(1.6152859e-05, dtype=float32), array(1.7046928e-05, dtype=float32), array(2.3543835e-05, dtype=float32), array(1.5079975e-05, dtype=float32), array(1.7285347e-05, dtype=float32), array(2.4020672e-05, dtype=float32), array(9.179115e-06, dtype=float32), array(2.3066998e-05, dtype=float32), array(1.8060207e-05, dtype=float32), array(1.013279e-05, dtype=float32), array(2.6583672e-05, dtype=float32), array(9.596348e-06, dtype=float32), array(2.092123e-05, dtype=float32), array(1.92523e-05, dtype=float32), array(1.0192394e-05, dtype=float32), array(2.7954578e-05, dtype=float32), array(1.0550022e-05, dtype=float32), array(1.9490719e-05, dtype=float32), array(1.9192696e-05, dtype=float32), array(1.090765e-05, dtype=float32), array(2.3663044e-05, dtype=float32), array(1.3530254e-05, dtype=float32), array(1.6868114e-05, dtype=float32), array(1.8954277e-05, dtype=float32), array(1.1026859e-05, dtype=float32), array(2.4020672e-05, dtype=float32), array(1.3947487e-05, dtype=float32), array(1.692772e-05, dtype=float32), array(1.7523766e-05, dtype=float32), array(1.1742115e-05, dtype=float32), array(2.2113323e-05, dtype=float32), array(1.513958e-05, dtype=float32), array(1.4901161e-05, dtype=float32), array(1.847744e-05, dtype=float32), array(1.1444092e-05, dtype=float32), array(2.1755695e-05, dtype=float32), array(1.41859055e-05, dtype=float32), array(1.5258789e-05, dtype=float32), array(1.8298626e-05, dtype=float32), array(1.1444092e-05, dtype=float32), array(2.1219254e-05, dtype=float32), array(1.3768673e-05, dtype=float32), array(1.50203705e-05, dtype=float32), array(1.7166138e-05, dtype=float32), array(1.0371208e-05, dtype=float32), array(2.169609e-05, dtype=float32), array(1.180172e-05, dtype=float32), array(1.603365e-05, dtype=float32), array(1.6450882e-05, dtype=float32), array(9.834766e-06, dtype=float32), array(2.0444393e-05, dtype=float32), array(1.04904175e-05, dtype=float32), array(1.6212463e-05, dtype=float32), array(1.4722347e-05, dtype=float32), array(1.013279e-05, dtype=float32), array(1.9669533e-05, dtype=float32), array(9.179115e-06, dtype=float32), array(1.692772e-05, dtype=float32), array(1.3113022e-05, dtype=float32), array(1.2874603e-05, dtype=float32), array(1.6629696e-05, dtype=float32), array(1.0788441e-05, dtype=float32), array(1.6212463e-05, dtype=float32), array(1.1146069e-05, dtype=float32), array(1.8239021e-05, dtype=float32), array(1.1622906e-05, dtype=float32), array(1.4305115e-05, dtype=float32), array(1.4424324e-05, dtype=float32), array(9.775162e-06, dtype=float32), array(1.7762184e-05, dtype=float32), array(9.357929e-06, dtype=float32), array(1.513958e-05, dtype=float32), array(1.1265278e-05, dtype=float32), array(1.5556812e-05, dtype=float32), array(1.21593475e-05, dtype=float32), array(1.3530254e-05, dtype=float32), array(1.3649464e-05, dtype=float32)], 'val_mse': [0.11293256282806396, 0.12261663377285004, 0.12916405498981476, 0.1338726431131363, 0.13766738772392273, 0.13926036655902863, 0.14072053134441376, 0.14906957745552063, 0.1701303869485855, 0.19870640337467194, 0.22188349068164825, 0.23447568714618683, 0.24067090451717377, 0.24402360618114471, 0.24593624472618103, 0.2474690079689026, 0.2485518604516983, 0.24958157539367676, 0.2505435049533844, 0.25116729736328125, 0.2515849769115448, 0.2519419193267822, 0.252209335565567, 0.25236961245536804, 0.2522304654121399, 0.2517436146736145, 0.2510508894920349, 0.25023698806762695, 0.24927471578121185, 0.24832189083099365, 0.24746467173099518, 0.24656398594379425, 0.2452494502067566, 0.24387840926647186, 0.24265404045581818, 0.24150098860263824, 0.24017049372196198, 0.2386617660522461, 0.23730027675628662, 0.23589099943637848, 0.23450951278209686, 0.2328920215368271, 0.23153509199619293, 0.2304089516401291, 0.2291845828294754, 0.2279093861579895, 0.2269187867641449, 0.2258022129535675, 0.22478313744068146, 0.2237526923418045, 0.22256754338741302, 0.22147798538208008, 0.22021642327308655, 0.21914458274841309, 0.21798767149448395, 0.2167769819498062, 0.21587350964546204, 0.2148437201976776, 0.21397186815738678, 0.21304643154144287, 0.21238890290260315, 0.21174034476280212, 0.21078673005104065, 0.20988424122333527, 0.20917899906635284, 0.2083059698343277, 0.20768313109874725, 0.20690669119358063, 0.20620404183864594, 0.20562106370925903, 0.2048233151435852, 0.20421913266181946, 0.2034287303686142, 0.20289260149002075, 0.20240412652492523, 0.20192503929138184, 0.20136964321136475, 0.20092906057834625, 0.2003488689661026, 0.19988848268985748, 0.199151411652565, 0.19857385754585266, 0.19812221825122833, 0.19791726768016815, 0.19777435064315796, 0.1977205127477646, 0.19743980467319489, 0.19723089039325714, 0.1969870775938034, 0.1970340460538864, 0.19679544866085052, 0.19675831496715546, 0.19656217098236084, 0.19626964628696442, 0.19619300961494446, 0.19600194692611694, 0.19591346383094788, 0.19573813676834106, 0.19562244415283203, 0.19538705050945282, 0.1952475905418396, 0.1947862058877945, 0.19461311399936676, 0.19410789012908936, 0.19376249611377716, 0.19319748878479004, 0.19271712005138397, 0.19222994148731232, 0.19153399765491486, 0.1912298947572708, 0.1908281147480011, 0.19045208394527435, 0.1900676190853119, 0.1896156668663025, 0.18931467831134796, 0.18918389081954956, 0.18890909850597382, 0.1886805295944214, 0.18814915418624878, 0.18782390654087067, 0.18748243153095245, 0.18712863326072693, 0.18697336316108704, 0.18684212863445282, 0.1863660365343094, 0.18616636097431183, 0.18559519946575165, 0.18521153926849365, 0.18470507860183716, 0.18408778309822083, 0.1834571808576584, 0.18300436437129974, 0.18283337354660034, 0.18260161578655243, 0.1824600100517273, 0.1823231726884842, 0.1822178214788437, 0.1822196990251541, 0.18229591846466064, 0.18229754269123077, 0.1823219656944275, 0.18198978900909424, 0.18165618181228638, 0.1811525672674179, 0.18058288097381592, 0.18002425134181976, 0.17958790063858032, 0.17938733100891113, 0.179282546043396, 0.17931751906871796, 0.17937149107456207, 0.1794005036354065, 0.17951072752475739, 0.17931880056858063, 0.17914700508117676, 0.1788591593503952, 0.17806795239448547, 0.17738276720046997, 0.17698515951633453, 0.1766432672739029, 0.1762656271457672, 0.1759025752544403, 0.17567452788352966, 0.17578275501728058, 0.17532934248447418, 0.17528636753559113, 0.17509184777736664, 0.17496027052402496, 0.17484737932682037, 0.17471668124198914, 0.17439036071300507, 0.17380578815937042, 0.17296332120895386, 0.17239442467689514, 0.1719551980495453, 0.17180898785591125, 0.1718330830335617, 0.17183567583560944, 0.17183494567871094, 0.17202773690223694, 0.17199283838272095, 0.17173780500888824, 0.17144426703453064, 0.17117726802825928, 0.17075446248054504, 0.17056488990783691, 0.17057183384895325, 0.17067928612232208, 0.17020350694656372, 0.1692650020122528, 0.16887055337429047, 0.1686490774154663, 0.16852490603923798, 0.16828250885009766, 0.16821184754371643, 0.1684935837984085, 0.16848672926425934, 0.16865327954292297, 0.16854192316532135, 0.1683332920074463, 0.16800692677497864, 0.1674710363149643, 0.16679805517196655, 0.1664862334728241, 0.16642232239246368, 0.16670683026313782, 0.1667529195547104, 0.16667667031288147, 0.16682125627994537, 0.16663844883441925, 0.16613444685935974, 0.16616427898406982, 0.16621658205986023, 0.16622154414653778, 0.16598114371299744, 0.16588079929351807, 0.16563203930854797, 0.16525259613990784, 0.16514772176742554, 0.16526968777179718, 0.16517220437526703, 0.16494658589363098, 0.16481025516986847, 0.16478371620178223, 0.16452600061893463, 0.16445395350456238, 0.16429352760314941, 0.16415606439113617, 0.16405539214611053, 0.16377881169319153, 0.1636970490217209, 0.1637403964996338, 0.1636783331632614, 0.1635059118270874, 0.16324730217456818, 0.16301830112934113, 0.16309577226638794, 0.1629122793674469, 0.16265109181404114, 0.16254107654094696, 0.16238360106945038, 0.16212698817253113, 0.16183580458164215, 0.1617591232061386, 0.1618833988904953, 0.16170069575309753, 0.16136391460895538, 0.16106683015823364, 0.16136857867240906, 0.16123060882091522, 0.1608506590127945, 0.16043418645858765, 0.1603577882051468, 0.16036231815814972, 0.16000999510288239, 0.1598331779241562, 0.15974482893943787, 0.15970905125141144, 0.15971063077449799, 0.1593841016292572, 0.15928494930267334, 0.15887954831123352, 0.15886186063289642, 0.1587255299091339, 0.15871724486351013, 0.15857218205928802, 0.15817420184612274, 0.15804143249988556, 0.1576271802186966, 0.15742500126361847, 0.15747232735157013, 0.15745675563812256, 0.1571211963891983, 0.1568402200937271, 0.15688197314739227, 0.15672354400157928, 0.15606734156608582, 0.15607546269893646, 0.15566445887088776, 0.15542657673358917, 0.15521959960460663, 0.15530462563037872, 0.15504390001296997, 0.15514717996120453, 0.1545553356409073, 0.15431620180606842, 0.1540031135082245, 0.15425065159797668, 0.15417596697807312, 0.1535869687795639, 0.15336129069328308, 0.1533065289258957, 0.1533903181552887, 0.15318511426448822, 0.15267305076122284, 0.15243907272815704, 0.1518469750881195, 0.15158338844776154, 0.15188245475292206, 0.15091992914676666, 0.15042085945606232, 0.1503702998161316, 0.14963743090629578, 0.1492503434419632, 0.1486588567495346, 0.14760741591453552, 0.14648959040641785, 0.14514069259166718, 0.14464621245861053, 0.14279921352863312, 0.14094680547714233, 0.13936255872249603, 0.13811512291431427, 0.13618400692939758, 0.13417334854602814, 0.13201391696929932, 0.12985175848007202, 0.127081960439682, 0.12426161766052246, 0.1219567060470581, 0.1191994696855545, 0.11563257873058319, 0.11267569661140442, 0.110174261033535, 0.1070622131228447, 0.10391639918088913, 0.09889734536409378, 0.09614201635122299, 0.09523166716098785, 0.09019868075847626, 0.08420733362436295, 0.08605165779590607, 0.08467204123735428, 0.07543094456195831, 0.08321070671081543, 0.08037611097097397, 0.09486427158117294, 0.08167529106140137, 0.20122194290161133, 0.07374878227710724, 0.15899792313575745, 0.13018377125263214, 0.07340757548809052, 0.20705148577690125, 0.15343230962753296, 0.07311966270208359, 0.08517228066921234, 0.06984207034111023, 0.059793490916490555, 0.10186148434877396, 0.09234515577554703, 0.06072206422686577, 0.06060728430747986, 0.058260299265384674, 0.05223286524415016, 0.07592544704675674, 0.09542078524827957, 0.05371055752038956, 0.0541544146835804, 0.05527450516819954, 0.04838884621858597, 0.09622196108102798, 0.09283872693777084, 0.045851271599531174, 0.05479104071855545, 0.05374930799007416, 0.04411037266254425, 0.12335235625505447, 0.084328293800354, 0.04492102563381195, 0.05424608662724495, 0.05277460813522339, 0.04247821494936943, 0.11040604114532471, 0.0772463008761406, 0.0433301143348217, 0.05167058855295181, 0.050244126468896866, 0.04067840427160263, 0.10605909675359726, 0.07345600426197052, 0.042282819747924805, 0.05057268962264061, 0.049699023365974426, 0.04157150909304619, 0.09547682851552963, 0.06937796622514725, 0.04486994817852974, 0.05230056867003441, 0.0480840839445591, 0.05737572908401489, 0.09393542259931564, 0.042396172881126404, 0.04829053953289986, 0.0497489869594574, 0.04403933137655258, 0.09597545862197876, 0.049230314791202545, 0.04946572333574295, 0.050437070429325104, 0.046456228941679, 0.0929289385676384, 0.04202932119369507, 0.05404225364327431, 0.05125395953655243, 0.08378525823354721, 0.08596295118331909, 0.046810898929834366, 0.05460963398218155, 0.04615538939833641, 0.09955926239490509, 0.05353042855858803, 0.050410088151693344, 0.05228022113442421, 0.07984521239995956, 0.09268780797719955, 0.049646783620119095, 0.0555637888610363, 0.049154505133628845, 0.11418528109788895, 0.06600522249937057, 0.05450773611664772, 0.054861098527908325, 0.04743295907974243, 0.11386049538850784, 0.04808987304568291, 0.05488003417849541, 0.056223031133413315, 0.061954475939273834, 0.1196594387292862, 0.045295339077711105, 0.056503552943468094, 0.056061938405036926, 0.05461571738123894, 0.11763588339090347, 0.05110088363289833, 0.06202077493071556, 0.05965127795934677, 0.053326282650232315, 0.1286468803882599, 0.0772048830986023, 0.058262843638658524, 0.060955967754125595, 0.05708777531981468, 0.10280176252126694, 0.10312386602163315, 0.05915100872516632, 0.06795522570610046, 0.06293261796236038, 0.07523532211780548, 0.1109803095459938, 0.06842198222875595, 0.07091821730136871, 0.07117031514644623, 0.0671132355928421, 0.13311760127544403, 0.08005410432815552, 0.06760355830192566, 0.07087282091379166, 0.06611400097608566, 0.12933188676834106, 0.0940069928765297, 0.06013642996549606, 0.0704110711812973, 0.06703624874353409, 0.07836474478244781, 0.09498795121908188, 0.06294507533311844, 0.0626491904258728, 0.07528869062662125, 0.06624769419431686, 0.08396963030099869, 0.073865607380867, 0.06217119097709656, 0.09749233722686768, 0.06347199529409409, 0.07105259597301483, 0.09750927984714508, 0.08959385752677917, 0.07796762138605118, 0.0697745531797409, 0.0654313936829567, 0.05750616639852524, 0.10776235163211823, 0.0761275440454483, 0.0567292794585228, 0.06007789075374603, 0.07571779191493988, 0.08996443450450897, 0.07332180440425873, 0.0636015310883522, 0.05752016231417656, 0.09192060679197311, 0.05877832695841789, 0.07254538685083389, 0.07782649248838425, 0.07975982129573822, 0.08172444999217987, 0.06455571949481964, 0.06207878887653351, 0.09017642587423325, 0.08922508358955383, 0.05495186150074005, 0.06621420383453369, 0.06554281711578369, 0.08424363285303116, 0.07676835358142853, 0.06756023317575455, 0.06338127702474594, 0.08232332766056061, 0.06168494373559952, 0.07458199560642242, 0.08010721951723099, 0.07977824658155441, 0.07468552142381668, 0.07049500197172165, 0.06477289646863937, 0.09432866424322128, 0.07914120703935623, 0.06477449834346771, 0.06698261946439743, 0.07044379413127899, 0.0848543718457222, 0.07408913224935532, 0.0636015236377716, 0.07384856045246124, 0.06693228334188461, 0.07704267650842667, 0.07772929221391678, 0.0703873485326767, 0.07161124795675278, 0.0630270391702652, 0.08176441490650177, 0.07993188500404358, 0.0684499442577362, 0.06725957244634628, 0.06452884525060654, 0.08415255695581436, 0.06734275817871094, 0.06985364854335785, 0.06675752252340317, 0.07790322601795197, 0.079938143491745, 0.06578405946493149, 0.07102566212415695, 0.06469009816646576, 0.08519376814365387, 0.07369202375411987, 0.07107685506343842, 0.06951399147510529, 0.07019010186195374, 0.08438082784414291, 0.0653546079993248, 0.0748424157500267, 0.06546650826931, 0.08351302891969681, 0.07595597207546234, 0.07292664796113968, 0.06840502470731735, 0.06820216029882431, 0.08067652583122253, 0.06469492614269257, 0.07162075489759445, 0.06324679404497147, 0.08404819667339325, 0.07017550617456436, 0.07157694548368454, 0.06767649948596954, 0.07730169594287872, 0.07797244936227798, 0.06659820675849915, 0.0725293830037117, 0.06419183313846588, 0.08172862231731415, 0.06341403722763062, 0.07549170404672623, 0.06795748323202133, 0.08107832074165344, 0.07760296016931534, 0.07205671072006226, 0.07232143729925156, 0.06301698088645935, 0.08558602631092072, 0.06323792785406113, 0.07331079244613647, 0.06733009219169617, 0.08338789641857147, 0.07473032176494598, 0.07083669304847717, 0.07340475171804428, 0.06685298681259155, 0.07933944463729858, 0.06334159523248672, 0.07436978071928024, 0.06391941756010056, 0.08067147433757782, 0.07162836194038391, 0.07265778630971909, 0.06890572607517242, 0.07547254115343094, 0.07700901478528976, 0.06637348234653473, 0.0725465714931488, 0.06349023431539536, 0.07920052856206894, 0.06326685100793839, 0.07386137545108795, 0.06531498581171036, 0.0796918198466301, 0.0714205652475357, 0.07197127491235733, 0.06820520758628845, 0.07387170940637589, 0.07442378252744675, 0.06898760050535202, 0.07020118087530136, 0.06447603553533554, 0.07768012583255768, 0.06546495854854584, 0.0711417943239212, 0.06372393667697906, 0.08079492300748825, 0.06572868674993515, 0.07007395476102829, 0.06709092855453491, 0.08103866130113602, 0.06994374841451645, 0.07069706171751022, 0.06936919689178467, 0.07406162470579147, 0.07410795986652374, 0.06860712170600891, 0.06944213062524796, 0.0677625983953476, 0.07695940881967545, 0.06535293906927109, 0.0713329091668129, 0.0648881122469902, 0.07533086091279984, 0.06816115975379944, 0.069558285176754, 0.06472887843847275, 0.07701438665390015, 0.06443369388580322, 0.07023794949054718, 0.0644889771938324, 0.07550771534442902, 0.06376251578330994, 0.07172778248786926, 0.06408511102199554, 0.07666120678186417, 0.06678947061300278, 0.06848448514938354, 0.06406570971012115, 0.08121231943368912, 0.06342130154371262, 0.06712128967046738, 0.06984695047140121, 0.07119081169366837, 0.06432587653398514, 0.07020214945077896, 0.06530065089464188, 0.07114212960004807, 0.06837602704763412, 0.06643678992986679, 0.06806731224060059, 0.07303639501333237, 0.06554193049669266, 0.06617723405361176, 0.07638206332921982, 0.06829318404197693, 0.06661577522754669, 0.06478172540664673, 0.07315491139888763, 0.06480246782302856, 0.06928622722625732, 0.06470470130443573, 0.07303675264120102, 0.06623753160238266, 0.06740963459014893, 0.06436996161937714, 0.0764470174908638, 0.06663523614406586, 0.06367101520299911, 0.07504148781299591, 0.06905366480350494, 0.06410573422908783, 0.06750333309173584, 0.07001948356628418, 0.06578068435192108, 0.07052470743656158, 0.06298792362213135, 0.07191991060972214, 0.07257091253995895, 0.06300421804189682, 0.07236970216035843, 0.06714379042387009, 0.06179127097129822, 0.07298792153596878, 0.06370016187429428, 0.06591931730508804, 0.0700012743473053, 0.06488116085529327, 0.08102484047412872, 0.06227225065231323, 0.0665995329618454, 0.0643802285194397, 0.06348348408937454, 0.07370813190937042, 0.06198606640100479, 0.06520210951566696, 0.06591939181089401, 0.06231408566236496, 0.08005783706903458, 0.06221039965748787, 0.06860334426164627, 0.06516110152006149, 0.06164903566241264, 0.0778462216258049, 0.06179599463939667, 0.06948689371347427, 0.06471670418977737, 0.0631733164191246, 0.07993441820144653, 0.06440814584493637, 0.07035721838474274, 0.06268082559108734, 0.061047378927469254, 0.07482215017080307, 0.0626688003540039, 0.07887088507413864, 0.061234861612319946, 0.06283985078334808, 0.07052610069513321, 0.06130480393767357, 0.07962469756603241, 0.06120501831173897, 0.06365589052438736, 0.07122649252414703, 0.06268802285194397, 0.0856127142906189, 0.061923447996377945, 0.06622075289487839, 0.06484320014715195, 0.06226538494229317, 0.08463562279939651, 0.06246237829327583, 0.0745416060090065, 0.06131434068083763, 0.06270727515220642, 0.09999358654022217, 0.0665213018655777, 0.060839954763650894, 0.08474354445934296, 0.05937023460865021, 0.10521502792835236, 0.09743142127990723, 0.08024158328771591, 0.06420841813087463, 0.13642846047878265, 0.08395201712846756, 0.06324520707130432, 0.059791211038827896, 0.06615302711725235, 0.10883468389511108, 0.05968071520328522, 0.05925052985548973, 0.06243104860186577, 0.1370466947555542, 0.061784569174051285, 0.06472844630479813, 0.055881042033433914, 0.09486759454011917, 0.07182053476572037, 0.05870150774717331, 0.057853974401950836, 0.09282530844211578, 0.10909063369035721, 0.058808863162994385, 0.058457307517528534, 0.05079580470919609, 0.1075911819934845, 0.05131681263446808, 0.05698811262845993, 0.05604613199830055, 0.10562467575073242, 0.10533279925584793, 0.056349605321884155, 0.054984573274850845, 0.05129731819033623, 0.11787985265254974, 0.0764661654829979, 0.06186017766594887, 0.05987747386097908, 0.05351857468485832, 0.14217758178710938, 0.05056913569569588, 0.0632365345954895, 0.0597127228975296, 0.05115818604826927, 0.12567999958992004, 0.06503641605377197, 0.056449417024850845, 0.056823939085006714, 0.054026734083890915, 0.11401204019784927, 0.08916735649108887, 0.057444799691438675, 0.05559909716248512, 0.05312826856970787, 0.09290947765111923, 0.09686092287302017, 0.0582561120390892, 0.06046910583972931, 0.05435152351856232, 0.11205916106700897, 0.08556783199310303, 0.05781736969947815, 0.057797446846961975, 0.05228681117296219, 0.13508053123950958, 0.077762670814991, 0.062482383102178574, 0.06076783686876297, 0.050919756293296814, 0.12193641811609268, 0.08373155444860458, 0.05743036046624184, 0.053714338690042496, 0.052208006381988525, 0.11407247185707092, 0.09577980637550354, 0.05930950492620468, 0.06138969212770462, 0.05401815101504326, 0.10189715772867203, 0.10849416255950928, 0.054997172206640244, 0.0625530406832695, 0.056892845779657364, 0.09638170897960663, 0.11989414691925049, 0.0515785813331604, 0.05827503278851509, 0.05633031204342842, 0.060671914368867874, 0.12650135159492493, 0.05239008367061615, 0.06340289115905762, 0.059357721358537674, 0.052904222160577774, 0.136227548122406, 0.06546176224946976, 0.06552862375974655, 0.06137700378894806, 0.05243942141532898, 0.12968888878822327, 0.09713100641965866, 0.056908443570137024, 0.05755632370710373, 0.05624530464410782, 0.09215027093887329, 0.12477807700634003, 0.04776526242494583, 0.05863981321454048, 0.057885896414518356, 0.05096110701560974, 0.1323615461587906, 0.09339477121829987, 0.0579642653465271, 0.057906944304704666, 0.056763906031847, 0.08386120200157166, 0.12510769069194794, 0.04962683096528053, 0.06361518055200577, 0.060384351760149, 0.05078980326652527, 0.1262224167585373, 0.09159015864133835, 0.05864730104804039, 0.06312378495931625, 0.058141034096479416, 0.08939485996961594, 0.12778136134147644, 0.048706162720918655, 0.05469170957803726, 0.058163248002529144, 0.05183955281972885, 0.1257895827293396, 0.09614633768796921, 0.05703001841902733, 0.061067596077919006, 0.05801773443818092, 0.06468242406845093, 0.12834152579307556, 0.05897698923945427, 0.06286612153053284, 0.05722983181476593, 0.05307789519429207, 0.11899174004793167, 0.10338688641786575, 0.052641186863183975, 0.0626147985458374, 0.05822106450796127, 0.05332427844405174, 0.12854737043380737, 0.06940726190805435, 0.05319099873304367, 0.05962036922574043, 0.05475349724292755, 0.10154475271701813, 0.10941897332668304, 0.04791887477040291, 0.05761804059147835, 0.05782168358564377, 0.05061337351799011, 0.12311024963855743, 0.07245410978794098, 0.06122862547636032, 0.06042274087667465, 0.05336714908480644, 0.10409297049045563, 0.10147041082382202, 0.049779146909713745, 0.06172136217355728, 0.05830257758498192, 0.06116528809070587, 0.11744718253612518, 0.05574382469058037, 0.06006860360503197, 0.0581098347902298, 0.049384333193302155, 0.1131884977221489, 0.07634738832712173, 0.0573393851518631, 0.06054377183318138, 0.051872462034225464, 0.11373160034418106, 0.08440733700990677, 0.05662728473544121, 0.0599212683737278, 0.052202753722667694, 0.09907916188240051, 0.09090981632471085, 0.052494704723358154, 0.05714133009314537, 0.053609758615493774, 0.10121099650859833, 0.09469107538461685, 0.053172767162323, 0.051958005875349045, 0.054073724895715714, 0.09216491878032684, 0.09703163057565689, 0.049590785056352615, 0.05851107835769653, 0.0535888634622097, 0.09207762032747269, 0.09483981132507324, 0.050970111042261124, 0.057962387800216675, 0.05353361368179321, 0.09128087759017944, 0.09146172553300858, 0.050503652542829514, 0.05412377044558525, 0.0522899255156517, 0.09979721903800964, 0.0831514224410057, 0.05332334712147713, 0.0566299632191658, 0.04985161870718002, 0.09872037917375565, 0.07250859588384628, 0.054152801632881165, 0.054701682180166245, 0.04789278656244278, 0.10202305763959885, 0.056601233780384064, 0.05621880665421486, 0.055019866675138474, 0.05616515502333641, 0.09433894604444504, 0.04811367392539978, 0.05661684274673462, 0.052591972053050995, 0.08805352449417114, 0.07925184816122055, 0.05227230489253998, 0.05515484884381294, 0.04820486903190613, 0.09433387964963913, 0.0520942248404026, 0.05358845740556717, 0.05141449347138405, 0.0750604197382927, 0.07772904634475708, 0.05091704800724983, 0.055054549127817154]}\n",
            "CLSTM(\n",
            "  (encoder): Encoder(\n",
            "    (convNN): ConvNN(\n",
            "      (network): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (5): ReLU()\n",
            "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (7): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "        (8): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (9): ReLU()\n",
            "        (10): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (11): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "        (12): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (13): ReLU()\n",
            "        (14): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (15): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "        (16): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (17): ReLU()\n",
            "        (18): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (lstm): LSTM(512, 512, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (main): Sequential(\n",
            "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "      (1): ReLU()\n",
            "      (2): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (4): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (5): ReLU()\n",
            "      (6): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (8): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (9): ReLU()\n",
            "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (12): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (13): ReLU()\n",
            "      (14): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (16): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (17): Sigmoid()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# loading checkpoint if model fail\n",
        "# ckp_path = \"/content/drive/MyDrive/Capstone/Capstone_checkpoint_models/clstm_wasser_upsample_opti_1000_final.pt\"\n",
        "ckp_path = \"/content/drive/MyDrive/Capstone/Capstone_checkpoint_models/clstm_wasser_upsample_opti_1000_final_2.pt\"\n",
        "\n",
        "clstm = CLSTM(512)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "img_size = (288, 432, 3)\n",
        "discriminator = Discriminator(img_size=img_size, dim=16)\n",
        "\n",
        "# Initialize optimizers\n",
        "lr = 0.00001\n",
        "betas = (.9, .99)\n",
        "g_optimizer = optim.RMSprop(clstm.parameters(), lr = lr)\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr = lr)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "batch_train_num = 8\n",
        "batch_valid_num = 10\n",
        "batch_test_num= 10\n",
        "\n",
        "img_length = 2\n",
        "\n",
        "start_epoch, g_model, d_model, g_opt, d_opt, train_losses, valid_losses, lowest_val_loss = load_ckp(ckp_path, clstm, g_optimizer,discriminator,d_optimizer)\n",
        "print(g_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# continue training\n",
        "\n",
        "n_epochs = 1000\n",
        "checkpoint_path = \"/content/drive/MyDrive/Capstone/Capstone_checkpoint_models/clstm_wasser_upsample_opti_1000_final_2.pt\"\n",
        "best_model_path = \"/content/drive/MyDrive/Capstone/Capstone_models/clstm_wasser_upsample_opti_best_final_2.pt\"\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "trainer = Trainer(clstm, discriminator, g_optimizer, d_optimizer,train_losses,val_losses,criterion,\n",
        "                  lowest_val_loss, checkpoint_path, best_model_path,\n",
        "                  gp_weight = 0.1, use_cuda=torch.cuda.is_available())\n",
        "\n"
      ],
      "metadata": {
        "id": "_z7534xPVpos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.train(train_dl, start_epoch,  n_epochs, val_dl)"
      ],
      "metadata": {
        "id": "FfdKsXE4bnqy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}