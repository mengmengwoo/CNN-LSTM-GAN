{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mengmengwoo/CNN-LSTM-GAN/blob/main/CNN_LSTM_MSE_GAN_35Timepoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Author\n",
        "- **Meng-Hsuan (Michelle) Wu** (JHU)\n",
        "\n",
        "## Projects\n",
        "- Least Squares Mean Squared Generative Adversarial Network 35 timesteps training"
      ],
      "metadata": {
        "id": "IUBbfV4cx263"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K7SIv-uw7Qt",
        "outputId": "21edfd45-321d-449a-fd20-d30f4d4cea76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import os.path\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as fn\n",
        "import torch.nn as nn\n",
        "from torch import linalg as LA\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad as torch_grad\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import math\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import Dataset, random_split,TensorDataset\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import pickle\n",
        "import shutil\n",
        "from torchvision.utils import make_grid\n",
        "import imageio\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from matplotlib import cm\n",
        "from math import floor\n",
        "from torch.nn.modules.pooling import MaxPool2d\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8-QBpuuPRsf"
      },
      "source": [
        "# Loading Datapoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGZrAxE4oUBC"
      },
      "outputs": [],
      "source": [
        "num_input_pics = 7\n",
        "tot_pics_series = 100 #100\n",
        "num_series = 100\n",
        "img_channel = 3\n",
        "img_height = 288\n",
        "img_width = 432\n",
        "\n",
        "\n",
        "# num_train + num_val + num_test = num_series\n",
        "num_train = 80 # 80\n",
        "num_val = 10\n",
        "num_test = 10\n",
        "batch_train_num = 8\n",
        "batch_valid_num = 10\n",
        "batch_test_num = 10\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xRec1P2X4xo"
      },
      "outputs": [],
      "source": [
        "seq_train = torch.arange(0, num_train)\n",
        "seq_val = torch.arange(num_train, num_train + num_val)\n",
        "seq_test = torch.arange(100, 110)\n",
        "\n",
        "\n",
        "train_data = TensorDataset(seq_train)\n",
        "val_data = TensorDataset(seq_val)\n",
        "test_data = TensorDataset(seq_test)\n",
        "\n",
        "train_dl = DataLoader(train_data, batch_size = batch_train_num, shuffle = True)\n",
        "valid_dl = DataLoader(val_data,   batch_size = batch_valid_num, shuffle = False)\n",
        "test_dl = DataLoader(test_data,   batch_size = batch_test_num, shuffle = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuBvBJC6eBds"
      },
      "source": [
        "# Model (Generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwFE4LdpgCBf"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Bo4zUpEqA9E"
      },
      "outputs": [],
      "source": [
        "class ConvNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size = 2, stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(64,momentum=0.9),\n",
        "        nn.MaxPool2d(2),\n",
        "\n",
        "        nn.Conv2d(64, 128, kernel_size = 3, stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(128,momentum=0.9),\n",
        "        nn.MaxPool2d(3),\n",
        "\n",
        "        nn.Conv2d(128, 256, kernel_size = 2, stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(256,momentum=0.9),\n",
        "        nn.MaxPool2d(3),\n",
        "\n",
        "        nn.Conv2d(256, 256, kernel_size = 2, stride = 1),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.BatchNorm2d(256,momentum=0.9),\n",
        "        nn.MaxPool2d(3),\n",
        "\n",
        "        nn.Conv2d(256, 512, kernel_size = 3, stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    cnn_val = self.network(x)\n",
        "    return_val = F.max_pool2d(cnn_val, kernel_size=cnn_val.size()[2:])\n",
        "    return_val = torch.squeeze(return_val)\n",
        "    return return_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H55vd3TYgkv2"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.convNN = ConvNN()\n",
        "    self.lstm = nn.LSTM(input_size = 512, hidden_size = 512,\n",
        "                        batch_first = True, bidirectional = True,\n",
        "                        num_layers = 4, dropout = 0.2)\n",
        "\n",
        "  def forward(self, input):\n",
        "    batch_size = int(input.shape[0]/img_length)\n",
        "    in_features = self.convNN(input)\n",
        "    in_features = torch.reshape(in_features,(batch_size, img_length, 512))\n",
        "    output, (h_n, c_n) = self.lstm(in_features)\n",
        "    return h_n[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdaXG3I5f7u4"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aK6ivYlugAZ0"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels = 512, out_channels = 256,\n",
        "                               kernel_size = 4, stride = 1, padding = 0,\n",
        "                               bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "            nn.BatchNorm2d(256),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "            nn.BatchNorm2d(128),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 128, 4, 2, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "            nn.BatchNorm2d(128),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "            nn.BatchNorm2d(64),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
        "            nn.Sigmoid()\n",
        "\n",
        "        )\n",
        "    def forward(self, input):\n",
        "      return self.main(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXRHV4dyRsBL"
      },
      "source": [
        "# Discriminator (Critic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUniimJCR3NU"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "  # img_size = (32, 32, 1)\n",
        "  # dim = 16 # should be 64\n",
        "  def __init__(self, img_size, dim):\n",
        "      super(Discriminator, self).__init__()\n",
        "\n",
        "      self.img_size = img_size\n",
        "\n",
        "      self.image_to_features = nn.Sequential(\n",
        "          nn.Conv2d(self.img_size[2], dim, 4, 2, 1),\n",
        "          nn.LeakyReLU(0.2),\n",
        "          nn.Conv2d(dim, 2 * dim, 4, 2, 1),\n",
        "          nn.LeakyReLU(0.2),\n",
        "          nn.Conv2d(2 * dim, 4 * dim, 4, 2, 1),\n",
        "          nn.LeakyReLU(0.2),\n",
        "\n",
        "          nn.Conv2d(4 * dim, 8 * dim, 4, 2, 1),\n",
        "          nn.LeakyReLU(0.2),\n",
        "          nn.Conv2d(8 * dim, self.img_size[2], 4, 2, 1),\n",
        "\n",
        "          nn.Sigmoid()\n",
        "      )\n",
        "\n",
        "      self.features_to_prob = nn.Sequential(\n",
        "          nn.Linear(192, 1),\n",
        "          nn.Sigmoid()\n",
        "      )\n",
        "\n",
        "  def forward(self, input_data):\n",
        "    batch_size = input_data.size()[0]\n",
        "    n_channels = input_data.size()[1]\n",
        "    x = self.image_to_features(input_data)\n",
        "    x = x.view(batch_size, -1)\n",
        "    return self.features_to_prob(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TesEADzsglMZ"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4adeccjTJyv"
      },
      "outputs": [],
      "source": [
        "class CLSTM(nn.Module):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(CLSTM, self).__init__()\n",
        "    self.encoder = Encoder()\n",
        "    self.decoder = Decoder()\n",
        "    self.latent_dim = latent_dim\n",
        "  def forward(self, x):\n",
        "    y_hidden = self.encoder(x)\n",
        "    y_hidden = torch.unsqueeze(y_hidden,2)\n",
        "    y_hidden = torch.unsqueeze(y_hidden,3)\n",
        "    y_predict = self.decoder(y_hidden)\n",
        "    return y_predict\n",
        "  def sample_latent(self, num_samples):\n",
        "    return torch.randn((num_samples, self.latent_dim))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmHw4HIvkSaR"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJC6g3cUgNJ9"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "  def __init__(self, clstm, discriminator, gen_optimizer, dis_optimizer,\n",
        "               checkpoint_path, backup_model_path, img_channel,img_height,img_width,new_img_height,new_img_width,\n",
        "               train_mse,val_mse,train_g_loss,train_d_loss,val_g_loss,val_d_loss,\n",
        "               random_timestep,tot_pics_series,\n",
        "               num_input_pics,save_model_every = 200, print_every = 10,\n",
        "               use_cuda=True):\n",
        "\n",
        "    self.G = clstm\n",
        "\n",
        "    self.G_opt = gen_optimizer\n",
        "    self.D = discriminator\n",
        "    self.D_opt = dis_optimizer\n",
        "\n",
        "    self.checkpoint_path = checkpoint_path\n",
        "    self.backup_model_path = backup_model_path\n",
        "\n",
        "    self.img_channel = img_channel\n",
        "    self.old_img_height = img_height\n",
        "    self.old_img_width = img_width\n",
        "    self.new_img_height = new_img_height\n",
        "    self.new_img_width = new_img_width\n",
        "\n",
        "    self.num_input_pics = num_input_pics\n",
        "    self.tot_pics_series = tot_pics_series\n",
        "    self.start_time = self.num_input_pics\n",
        "    self.random_timestep = random_timestep\n",
        "\n",
        "\n",
        "    self.train_mse = train_mse\n",
        "    self.val_mse = val_mse\n",
        "    self.train_g_loss = train_g_loss\n",
        "    self.val_g_loss = val_g_loss\n",
        "    self.train_d_loss = train_d_loss\n",
        "    self.val_d_loss = val_d_loss\n",
        "\n",
        "    self.temp_train_d_loss = []\n",
        "    self.temp_train_g_loss = []\n",
        "    self.temp_val_d_loss = []\n",
        "    self.temp_val_g_loss = []\n",
        "\n",
        "    self.temp_train_mse = []\n",
        "    self.temp_val_mse = []\n",
        "\n",
        "    self.save_model_every = save_model_every\n",
        "    self.print_every = print_every\n",
        "\n",
        "    self.use_cuda = use_cuda\n",
        "\n",
        "\n",
        "\n",
        "    if self.use_cuda:\n",
        "        self.G = self.G.cuda()\n",
        "        self.D = self.D.cuda()\n",
        "\n",
        "\n",
        "  def _critic_train_iteration(self, y_pred, y_true, train):\n",
        "    batch_size = y_true.size()[0]\n",
        "    theoretical_real = torch.ones(batch_size,1) # this is b\n",
        "    theoretical_fake = torch.zeros(batch_size,1) # this is a\n",
        "    if self.use_cuda:\n",
        "      theoretical_real = theoretical_real.cuda()\n",
        "      theoretical_fake = theoretical_fake.cuda()\n",
        "\n",
        "    # Calculate probabilities on real and generated data\n",
        "    d_real = self.D(y_true)\n",
        "    d_generated = self.D(y_pred)\n",
        "\n",
        "    # Create total loss and optimize\n",
        "    if train:\n",
        "      self.D_opt.zero_grad()\n",
        "      d_real = d_real.view(batch_size, -1)\n",
        "      d_generated = d_generated.view(batch_size,-1)\n",
        "      real_loss = adversarial_loss(d_real, theoretical_real)\n",
        "      fake_loss = adversarial_loss(d_generated, theoretical_fake)\n",
        "      d_loss = (1/2)* (real_loss + fake_loss)\n",
        "\n",
        "      d_loss.backward(retain_graph = True)\n",
        "      self.D_opt.step()\n",
        "      self.temp_train_d_loss.append(d_loss.data.cpu().numpy())\n",
        "    else:\n",
        "      d_real = d_real.view(batch_size, -1)\n",
        "      d_generated = d_generated.view(batch_size,-1)\n",
        "      real_loss = adversarial_loss(d_real, theoretical_real)\n",
        "      fake_loss = adversarial_loss(d_generated, theoretical_fake)\n",
        "      d_loss = (1/2)* (real_loss + fake_loss)\n",
        "      self.temp_val_d_loss.append(d_loss.data.cpu().numpy())\n",
        "  def _generator_train_iteration(self, y_pred, y_true, train):\n",
        "    batch_size = y_true.size()[0]\n",
        "    theoretical_real = torch.ones(batch_size,1)\n",
        "    pixel_diff = adversarial_loss(y_true,y_pred)\n",
        "    if self.use_cuda:\n",
        "      theoretical_real = theoretical_real.cuda()\n",
        "    if train:\n",
        "      self.G_opt.zero_grad()\n",
        "      d_generated = self.D(y_pred)\n",
        "      g_loss = 0.5*(adversarial_loss(d_generated,theoretical_real) + pixel_diff)\n",
        "      g_loss.backward()\n",
        "      self.G_opt.step()\n",
        "\n",
        "      # Record loss\n",
        "      g_loss = g_loss.data.cpu().numpy()\n",
        "      self.temp_train_g_loss.append(g_loss)\n",
        "      self.temp_train_mse.append(pixel_diff)\n",
        "    else:\n",
        "      d_generated = self.D(y_pred)\n",
        "      g_loss = 0.5*(adversarial_loss(d_generated, theoretical_real) + pixel_diff)\n",
        "\n",
        "      # Record loss\n",
        "      g_loss = g_loss.data.cpu().numpy()\n",
        "      self.temp_val_g_loss.append(g_loss)\n",
        "      self.temp_val_mse.append(pixel_diff)\n",
        "  def _train_epoch(self,train_loader, train_data):\n",
        "\n",
        "    self.G.train()\n",
        "\n",
        "    train_batch_num = 0\n",
        "    for batch_train in train_loader:\n",
        "      curr_batch_train = train_data[train_batch_num]\n",
        "      train_batch_num +=1\n",
        "      for t in range(len(self.random_timestep)):\n",
        "        curr_y_time = self.random_timestep[t]\n",
        "        curr_x_start_time = curr_y_time-self.num_input_pics\n",
        "        x_train = curr_batch_train[:, curr_x_start_time: curr_y_time,:,:,: ]\n",
        "        y_train = curr_batch_train[:, curr_y_time, :,:,:]\n",
        "\n",
        "\n",
        "        if self.use_cuda:\n",
        "          x_train, y_train = x_train.cuda(), y_train.cuda()\n",
        "        x_train = fn.center_crop(x_train,output_size = [256])\n",
        "\n",
        "        n_series = x_train.shape[0]\n",
        "\n",
        "        x_train_new_dim = (n_series*self.num_input_pics, self.img_channel, self.new_img_height, self.new_img_width)\n",
        "        x_train_new = torch.reshape(x_train,x_train_new_dim)\n",
        "        y_train_predict = self.G(x_train_new)\n",
        "        y_train_crop = fn.center_crop(y_train, output_size=[256])\n",
        "        y_train_predict_crop = fn.center_crop(y_train_predict, output_size = [256])\n",
        "        self._critic_train_iteration(y_train_predict_crop, y_train_crop, train = True)\n",
        "        self._generator_train_iteration(y_train_predict_crop, y_train_crop, train = True)\n",
        "\n",
        "\n",
        "  def _validate(self, val_loader, val_data):\n",
        "\n",
        "    self.G.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      val_batch_num = 0\n",
        "\n",
        "      for batch_val in val_loader:\n",
        "        curr_batch_val = val_data[val_batch_num]\n",
        "        val_batch_num +=1\n",
        "        for t in range(len(self.random_timestep)):\n",
        "          curr_y_time = self.random_timestep[t]\n",
        "          curr_x_start_time = curr_y_time-self.num_input_pics\n",
        "          x_val = curr_batch_val[:, curr_x_start_time: curr_y_time,:,:,: ]\n",
        "          y_val = curr_batch_val[:, curr_y_time, :,:,:]\n",
        "          if self.use_cuda:\n",
        "            x_val, y_val = x_val.cuda(), y_val.cuda()\n",
        "          x_val = fn.center_crop(x_val,output_size = [256])\n",
        "\n",
        "          n_series = x_val.shape[0]\n",
        "\n",
        "          x_val_new_dim = (n_series*self.num_input_pics, self.img_channel, self.new_img_height, self.new_img_width)\n",
        "          x_val_new = torch.reshape(x_val,x_val_new_dim)\n",
        "          y_val_predict = self.G(x_val_new)\n",
        "          y_val_crop = fn.center_crop(y_val, output_size=[256])\n",
        "          y_val_predict_crop = fn.center_crop(y_val_predict, output_size = [256])\n",
        "          self._critic_train_iteration(y_val_predict_crop, y_val_crop, train = False)\n",
        "          self._generator_train_iteration(y_val_predict_crop, y_val_crop, train = False)\n",
        "\n",
        "\n",
        "  def _data_generator(self, y_index,num_series):\n",
        "    data = np.zeros(shape = (num_series, self.tot_pics_series, self.img_channel, self.old_img_height, self.old_img_width))\n",
        "    for y_idx in range(num_series):\n",
        "      model_path = \"/content/drive/MyDrive/Capstone/Capstone_data_jpg/\"+str(y_index[y_idx])\n",
        "      for entry in range(self.tot_pics_series):\n",
        "        img_path = model_path+'/'+\"{:02d}\".format(entry)+'im.jpg'\n",
        "        x_to_convert = Image.open(img_path)\n",
        "        x = np.asarray(x_to_convert)\n",
        "        x = np.moveaxis(x,-1,0) # change image dimension to channel first\n",
        "        data[y_idx][entry] = x\n",
        "    data = torch.tensor(np.array(data/255).astype(np.float32))\n",
        "    return data\n",
        "\n",
        "  def train(self, train_loader, start_epochs, n_epochs, validate_loader):\n",
        "    train_data = {}\n",
        "    val_data = {}\n",
        "    for epoch in range(start_epochs, n_epochs):\n",
        "\n",
        "      # load the data at the first epoch\n",
        "      if epoch == start_epochs:\n",
        "        val_batch_num = 0\n",
        "        train_batch_num = 0\n",
        "\n",
        "        for batch_train in train_loader:\n",
        "          y_idx = batch_train[0].tolist()\n",
        "          num_series = len(y_idx)\n",
        "          data_train = self._data_generator(y_idx, num_series)\n",
        "          train_data[train_batch_num] = data_train\n",
        "          train_batch_num +=1\n",
        "\n",
        "        for batch_val in validate_loader:\n",
        "          y_idx = batch_val[0].tolist()\n",
        "          num_series = len(y_idx)\n",
        "          data_val = self._data_generator(y_idx, num_series)\n",
        "          val_data[val_batch_num] = data_val\n",
        "          val_batch_num +=1\n",
        "        print(\"data complete!\")\n",
        "\n",
        "      self._train_epoch(train_loader,train_data)\n",
        "      self._validate(validate_loader,val_data)\n",
        "\n",
        "      avg_train_g_loss = sum(self.temp_train_g_loss) / len(self.temp_train_g_loss)\n",
        "      avg_train_d_loss = sum(self.temp_train_d_loss) / len(self.temp_train_d_loss)\n",
        "      avg_val_g_loss = sum(self.temp_val_g_loss) / len(self.temp_val_g_loss)\n",
        "      avg_val_d_loss = sum(self.temp_val_d_loss) / len(self.temp_val_d_loss)\n",
        "      avg_train_mse = sum(self.temp_train_mse)/len(self.temp_train_mse)\n",
        "      avg_val_mse = sum(self.temp_val_mse)/len(self.temp_val_mse)\n",
        "\n",
        "      if epoch % self.print_every == 0:\n",
        "        print(\"Iteration {}\".format(epoch + 1))\n",
        "        print(\"D: {}\".format(avg_train_d_loss))\n",
        "        print(\"val_D: {}\".format(avg_val_d_loss))\n",
        "        print(\"G: {}\".format(avg_train_d_loss))\n",
        "        print(\"val_G: {}\".format(avg_val_g_loss))\n",
        "        print(\"train_mse:{}\".format(avg_train_mse))\n",
        "        print(\"val_mse:{}\".format(avg_val_mse))\n",
        "\n",
        "      ##############\n",
        "      # checkpoint #\n",
        "      ##############\n",
        "      if self.use_cuda:\n",
        "        self.G, self.D,avg_train_mse, avg_val_mse = self.G.cpu(), self.D.cpu(), avg_train_mse.cpu().detach().numpy(), avg_val_mse.cpu().detach().numpy()\n",
        "      self.train_g_loss.append(avg_train_g_loss)\n",
        "      self.val_g_loss.append(avg_val_g_loss)\n",
        "      self.train_d_loss.append(avg_train_d_loss)\n",
        "      self.val_d_loss.append(avg_val_d_loss)\n",
        "      self.train_mse.append(avg_train_mse)\n",
        "      self.val_mse.append(avg_val_mse)\n",
        "      checkpoint = {\n",
        "        'epoch': epoch + 1,\n",
        "        'generator_state_dict': self.G.state_dict(),\n",
        "        'generator_optimizer': self.G_opt.state_dict(),\n",
        "        'discriminator_state_dict': self.D.state_dict(),\n",
        "        'discriminator_optimizer': self.D_opt.state_dict(),\n",
        "        'train_mse': self.train_mse,\n",
        "        'val_mse': self.val_mse,\n",
        "        'train_g_loss':self.train_g_loss,\n",
        "        'val_g_loss': self.val_g_loss,\n",
        "        'train_d_loss':self.train_d_loss,\n",
        "        'val_d_loss':self.val_d_loss\n",
        "        }\n",
        "      # save checkpoint\n",
        "      save_ckp(checkpoint, False, self.checkpoint_path)\n",
        "\n",
        "      # save another copy in case model corrupt\n",
        "      if epoch % self.save_model_every == 0:\n",
        "        backup_path = self.backup_model_path + \"/\"+ \"16_clstm_fix_lsgan_random_choice\"+str(epoch)+\".pt\"\n",
        "        save_ckp(checkpoint,False , backup_path)\n",
        "      self.temp_train_d_loss = []\n",
        "      self.temp_train_g_loss = []\n",
        "      self.temp_val_d_loss = []\n",
        "      self.temp_val_g_loss = []\n",
        "      self.temp_train_mse = []\n",
        "      self.temp_val_mse = []\n",
        "      if self.use_cuda:\n",
        "        self.G, self.D = self.G.cuda(), self.D.cuda()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzdRvV12o8xE"
      },
      "source": [
        "# Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRaE2Ci5o_u6"
      },
      "outputs": [],
      "source": [
        "def save_ckp(state, is_best, checkpoint_path):\n",
        "  f_path = checkpoint_path\n",
        "  torch.save(state, f_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLJe-iq3a4PC"
      },
      "outputs": [],
      "source": [
        "def load_ckp(checkpoint_fpath, gen_model, gen_opt, discrim_model, discrim_opt):\n",
        "    device = torch.device(\"cuda\")\n",
        "    # load check point\n",
        "    checkpoint = torch.load(checkpoint_fpath,map_location=\"cuda:0\")\n",
        "    # initialize state_dict from checkpoint to model\n",
        "    gen_model.load_state_dict(checkpoint['generator_state_dict'])\n",
        "    discrim_model.load_state_dict(checkpoint['discriminator_state_dict'])\n",
        "    gen_model = gen_model.to(device)\n",
        "    discrim_model = discrim_model.to(device)\n",
        "    # initialize optimizer from checkpoint to optimizer\n",
        "    gen_opt.load_state_dict(checkpoint['generator_optimizer'])\n",
        "    discrim_opt.load_state_dict(checkpoint['discriminator_optimizer'])\n",
        "\n",
        "    # mse\n",
        "    train_mse = checkpoint['train_mse']\n",
        "    val_mse = checkpoint['val_mse']\n",
        "\n",
        "    # other loss\n",
        "    train_g_loss = checkpoint['train_g_loss']\n",
        "    train_d_loss = checkpoint['train_d_loss']\n",
        "    val_g_loss = checkpoint['val_g_loss']\n",
        "    val_d_loss = checkpoint['val_d_loss']\n",
        "\n",
        "\n",
        "    # return model, optimizer, epoch value, min validation loss\n",
        "    return checkpoint['epoch'], gen_model, discrim_model, gen_opt, discrim_opt, train_mse, val_mse, train_g_loss, train_d_loss, val_g_loss, val_d_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6EnGnLFgnke"
      },
      "source": [
        "# Setting Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbXUjgd6XYmR",
        "outputId": "86f08a11-f0b9-4c37-8c78-ec715d6be49f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7, 25, 80, 16, 40, 23, 71, 65, 68, 91, 56, 34, 20, 70, 11, 57, 63, 8, 93, 42, 37, 21, 48, 86, 10, 77, 9, 90, 35, 62, 54, 74, 41, 22, 73]\n",
            "35\n",
            "CLSTM(\n",
            "  (encoder): Encoder(\n",
            "    (convNN): ConvNN(\n",
            "      (network): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (5): ReLU()\n",
            "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (7): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "        (8): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (9): ReLU()\n",
            "        (10): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (11): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "        (12): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (13): ReLU()\n",
            "        (14): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (15): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "        (16): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (17): ReLU()\n",
            "        (18): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (lstm): LSTM(512, 512, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (main): Sequential(\n",
            "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "      (1): ReLU()\n",
            "      (2): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (4): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (5): ReLU()\n",
            "      (6): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (8): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (9): ReLU()\n",
            "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (12): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (13): ReLU()\n",
            "      (14): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (16): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (17): Sigmoid()\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Discriminator(\n",
            "  (image_to_features): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): LeakyReLU(negative_slope=0.2)\n",
            "    (4): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "    (6): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (7): LeakyReLU(negative_slope=0.2)\n",
            "    (8): Conv2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (9): Sigmoid()\n",
            "  )\n",
            "  (features_to_prob): Sequential(\n",
            "    (0): Linear(in_features=192, out_features=1, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "# setting parameters\n",
        "\n",
        "num_input_pics = 7\n",
        "tot_pics_series = 100\n",
        "\n",
        "\n",
        "start_epoch = 0\n",
        "n_epochs = 1000\n",
        "\n",
        "img_channel = 3\n",
        "img_height = 288\n",
        "img_width = 432\n",
        "\n",
        "new_img_height = 256\n",
        "new_img_width = 256\n",
        "\n",
        "random.seed(1)\n",
        "random_timestep = [num_input_pics]\n",
        "\n",
        "random_timestep_num = 35\n",
        "numbers = random.sample(range(num_input_pics+1, tot_pics_series), random_timestep_num-1)\n",
        "random_timestep.extend(numbers)\n",
        "print(random_timestep)\n",
        "print(len(random_timestep))\n",
        "\n",
        "img_length = num_input_pics\n",
        "clstm = CLSTM(512)\n",
        "\n",
        "img_size = (288, 432, 3)\n",
        "lr = 0.00001\n",
        "discriminator = Discriminator(img_size=img_size, dim=16)\n",
        "g_optimizer = optim.RMSprop(clstm.parameters(), lr = lr)\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr = lr)\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/Capstone/Capstone_models/16_clstm_fix_lsgan_random_choice.pt\"\n",
        "backup_model_path = \"/content/drive/MyDrive/Capstone/Capstone_checkpoint_models\"\n",
        "\n",
        "\n",
        "\n",
        "train_mse = []\n",
        "val_mse = []\n",
        "train_g_loss = []\n",
        "val_g_loss = []\n",
        "train_d_loss = []\n",
        "val_d_loss = []\n",
        "\n",
        "print(clstm)\n",
        "print(discriminator)\n",
        "\n",
        "save_model_every = 100\n",
        "\n",
        "print_every = 10\n",
        "\n",
        "adversarial_loss = torch.nn.MSELoss()\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "trainer = Trainer(clstm, discriminator, g_optimizer, d_optimizer, checkpoint_path,\n",
        "                  backup_model_path, img_channel, img_height, img_width, new_img_height, new_img_width,\n",
        "                  train_mse, val_mse, train_g_loss, train_d_loss, val_g_loss, val_d_loss, random_timestep,tot_pics_series,\n",
        "                  num_input_pics, save_model_every, print_every, use_cuda=torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whMlbD2DjHEe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# trainer.train(train_dl, start_epoch,  n_epochs, valid_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYdY3hzjPXXf"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2k-9tnynux6",
        "outputId": "dca325eb-6e88-4d95-ecef-82b36c557e33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLSTM(\n",
            "  (encoder): Encoder(\n",
            "    (convNN): ConvNN(\n",
            "      (network): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (5): ReLU()\n",
            "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (7): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "        (8): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (9): ReLU()\n",
            "        (10): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (11): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "        (12): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (13): ReLU()\n",
            "        (14): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (15): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "        (16): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (17): ReLU()\n",
            "        (18): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (lstm): LSTM(512, 512, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (main): Sequential(\n",
            "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "      (1): ReLU()\n",
            "      (2): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (4): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (5): ReLU()\n",
            "      (6): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (8): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (9): ReLU()\n",
            "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (12): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (13): ReLU()\n",
            "      (14): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (16): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (17): Sigmoid()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# loading checkpoint if model fail\n",
        "ckp_path = \"/content/drive/MyDrive/Capstone/Capstone_checkpoint_models/16_clstm_fix_lsgan_random_choice500.pt\"\n",
        "backup_model_path = \"/content/drive/MyDrive/Capstone/Capstone_checkpoint_models\"\n",
        "clstm = CLSTM(512)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "img_size = (288, 432, 3)\n",
        "discriminator = Discriminator(img_size=img_size, dim=16)\n",
        "\n",
        "# Initialize optimizers\n",
        "lr = 0.00001\n",
        "adversarial_loss = torch.nn.MSELoss()\n",
        "g_optimizer = optim.RMSprop(clstm.parameters(), lr = lr)\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr = lr)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "batch_train_num = 8\n",
        "batch_valid_num = 10\n",
        "batch_test_num= 10\n",
        "\n",
        "img_length = num_input_pics\n",
        "\n",
        "start_epoch, g_model, d_model, g_opt, d_opt,train_mse, val_mse,train_g_loss, train_d_loss, val_g_loss, val_d_loss= load_ckp(ckp_path, clstm, g_optimizer,discriminator,d_optimizer)\n",
        "print(g_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXahf7UG-Hcf"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(clstm, discriminator, g_optimizer, d_optimizer, ckp_path,\n",
        "                  backup_model_path, img_channel, img_height, img_width, new_img_height, new_img_width,\n",
        "                  train_mse, val_mse,train_g_loss, train_d_loss, val_g_loss, val_d_loss, random_timestep,tot_pics_series,\n",
        "                  num_input_pics, save_model_every=100, print_every=10, use_cuda=torch.cuda.is_available())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnltxCOAizho"
      },
      "outputs": [],
      "source": [
        "# continue training\n",
        "#trainer.train(train_dl, start_epoch,  n_epochs, valid_dl)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
