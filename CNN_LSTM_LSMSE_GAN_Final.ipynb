{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mengmengwoo/CNN-LSTM-GAN/blob/main/CNN_LSTM_MSE_GAN_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Author\n",
        "- **Meng-Hsuan (Michelle) Wu** (JHU)\n",
        "\n",
        "## Projects\n",
        "- CNN-LSTM with Least Squares Mean Squared Generative Adversarial Network"
      ],
      "metadata": {
        "id": "aFbItNZvAFXw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K7SIv-uw7Qt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d85af616-f10c-437a-c235-5dee613d710a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import os.path\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as fn\n",
        "import torch.nn as nn\n",
        "from torch import linalg as LA\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad as torch_grad\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import math\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import pickle\n",
        "import shutil\n",
        "from torchvision.utils import make_grid\n",
        "import imageio\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from matplotlib import cm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuBvBJC6eBds"
      },
      "source": [
        "# Model (Generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwFE4LdpgCBf"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.pooling import MaxPool2d\n",
        "class ConvNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size = 2, stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(64,momentum=0.9),\n",
        "        nn.MaxPool2d(2),\n",
        "\n",
        "        nn.Conv2d(64, 128, kernel_size = 3, stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(128,momentum=0.9),\n",
        "        nn.MaxPool2d(3),\n",
        "\n",
        "        nn.Conv2d(128, 256, kernel_size = 2, stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(256,momentum=0.9),\n",
        "        nn.MaxPool2d(3),\n",
        "\n",
        "        nn.Conv2d(256, 256, kernel_size = 2, stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(256,momentum=0.9),\n",
        "        nn.MaxPool2d(3),\n",
        "\n",
        "        nn.Conv2d(256, 512, kernel_size = 3, stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    cnn_val = self.network(x)\n",
        "    return_val = F.max_pool2d(cnn_val, kernel_size=cnn_val.size()[2:])\n",
        "    return_val = torch.squeeze(return_val)\n",
        "    return return_val"
      ],
      "metadata": {
        "id": "8Bo4zUpEqA9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H55vd3TYgkv2"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.convNN = ConvNN()\n",
        "    self.lstm = nn.LSTM(input_size = 512, hidden_size = 512,\n",
        "                        batch_first = True, bidirectional = True,\n",
        "                        num_layers = 4, dropout = 0.2)\n",
        "\n",
        "  def forward(self, input):\n",
        "    batch_size = int(input.shape[0]/img_length)\n",
        "\n",
        "    in_features = self.convNN(input)\n",
        "    in_features = torch.reshape(in_features,(batch_size, img_length, 512))\n",
        "    output, (h_n, c_n) = self.lstm(in_features)\n",
        "    return h_n[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdaXG3I5f7u4"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aK6ivYlugAZ0"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels = 512, out_channels = 256,\n",
        "                               kernel_size = 4, stride = 1, padding = 0,\n",
        "                               bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "            nn.BatchNorm2d(256),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "            nn.BatchNorm2d(128),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 128, 4, 2, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "            nn.BatchNorm2d(128),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "            nn.BatchNorm2d(64),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
        "            nn.Sigmoid()\n",
        "\n",
        "        )\n",
        "    def forward(self, input):\n",
        "      return self.main(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator (Critic)"
      ],
      "metadata": {
        "id": "FXRHV4dyRsBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "  def __init__(self, img_size, dim):\n",
        "      super(Discriminator, self).__init__()\n",
        "\n",
        "      self.img_size = img_size\n",
        "\n",
        "      self.image_to_features = nn.Sequential(\n",
        "          nn.Conv2d(self.img_size[2], dim, 4, 2, 1),\n",
        "          nn.LeakyReLU(0.2),\n",
        "          nn.Conv2d(dim, 2 * dim, 4, 2, 1),\n",
        "          nn.LeakyReLU(0.2),\n",
        "          nn.Conv2d(2 * dim, 4 * dim, 4, 2, 1),\n",
        "          nn.LeakyReLU(0.2),\n",
        "          nn.Conv2d(4 * dim, 8 * dim, 4, 2, 1),\n",
        "          nn.LeakyReLU(0.2),\n",
        "          nn.Conv2d(8 * dim, self.img_size[2], 4, 2, 1),\n",
        "          nn.Sigmoid()\n",
        "      )\n",
        "      self.features_to_prob = nn.Sequential(\n",
        "          nn.Linear(192, 1),\n",
        "          nn.Sigmoid()\n",
        "      )\n",
        "\n",
        "  def forward(self, input_data):\n",
        "    batch_size = input_data.size()[0]\n",
        "    n_channels = input_data.size()[1]\n",
        "    x = self.image_to_features(input_data)\n",
        "    x = x.view(batch_size, -1)\n",
        "    return self.features_to_prob(x)\n"
      ],
      "metadata": {
        "id": "kUniimJCR3NU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TesEADzsglMZ"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4adeccjTJyv"
      },
      "outputs": [],
      "source": [
        "class CLSTM(nn.Module):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(CLSTM, self).__init__()\n",
        "    self.encoder = Encoder()\n",
        "    self.decoder = Decoder()\n",
        "    self.latent_dim = latent_dim\n",
        "  def forward(self, x):\n",
        "    y_hidden = self.encoder(x)\n",
        "    y_hidden = torch.unsqueeze(y_hidden,2)\n",
        "    y_hidden = torch.unsqueeze(y_hidden,3)\n",
        "    y_predict = self.decoder(y_hidden)\n",
        "    return y_predict\n",
        "  def sample_latent(self, num_samples):\n",
        "    return torch.randn((num_samples, self.latent_dim))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmHw4HIvkSaR"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Trainer():\n",
        "\n",
        "  def __init__(self, clstm, discriminator, gen_optimizer, dis_optimizer,train_mse,\n",
        "               val_mse, train_g_loss,val_g_loss,train_d_loss,val_d_loss,\n",
        "               checkpoint_path, best_model_path, save_model_every,valid_mse_min,\n",
        "               print_every = 10,\n",
        "               use_cuda=True):\n",
        "    self.G = clstm\n",
        "    self.G_opt = gen_optimizer\n",
        "    self.D = discriminator\n",
        "    self.D_opt = dis_optimizer\n",
        "\n",
        "    self.train_mse = train_mse\n",
        "    self.val_mse = val_mse\n",
        "    self.train_g_loss = train_g_loss\n",
        "    self.val_g_loss = val_g_loss\n",
        "    self.train_d_loss = train_d_loss\n",
        "    self.val_d_loss = val_d_loss\n",
        "\n",
        "    self.temp_train_d_loss = []\n",
        "    self.temp_train_g_loss = []\n",
        "    self.temp_val_d_loss = []\n",
        "    self.temp_val_g_loss = []\n",
        "    self.temp_train_mse = []\n",
        "    self.temp_val_mse = []\n",
        "\n",
        "    self.use_cuda = use_cuda\n",
        "\n",
        "    self.checkpoint_path = checkpoint_path\n",
        "    self.best_model_path = best_model_path\n",
        "\n",
        "    self.print_every = print_every\n",
        "    self.save_model_every = save_model_every\n",
        "    self.valid_mse_min = valid_mse_min\n",
        "\n",
        "\n",
        "    if self.use_cuda:\n",
        "        self.G = self.G.cuda()\n",
        "        self.D = self.D.cuda()\n",
        "\n",
        "\n",
        "  def _critic_train_iteration(self, y_pred, y_true, train):\n",
        "    # Get generated data\n",
        "    batch_size = y_true.size()[0]\n",
        "    theoretical_real = torch.ones(batch_size,1)\n",
        "    theoretical_fake = torch.zeros(batch_size,1)\n",
        "    if self.use_cuda:\n",
        "      theoretical_real = theoretical_real.cuda()\n",
        "      theoretical_fake = theoretical_fake.cuda()\n",
        "\n",
        "    # Calculate probabilities on real and generated data\n",
        "    d_real = self.D(y_true)\n",
        "    d_generated = self.D(y_pred)\n",
        "    pixel_diff = adversarial_loss(y_true,y_pred)\n",
        "\n",
        "    # Create total loss and optimize\n",
        "    if train:\n",
        "      # Get gradient penalty\n",
        "      self.D_opt.zero_grad()\n",
        "      d_real = d_real.view(batch_size, -1)\n",
        "      d_generated = d_generated.view(batch_size,-1)\n",
        "      real_loss = adversarial_loss(d_real, theoretical_real)\n",
        "      fake_loss = adversarial_loss(d_generated, theoretical_fake)\n",
        "      d_loss = (1/2)* (real_loss + fake_loss)\n",
        "\n",
        "      d_loss.backward(retain_graph = True)\n",
        "      self.D_opt.step()\n",
        "      self.temp_train_d_loss.append(d_loss.data.cpu().numpy())\n",
        "    else:\n",
        "      d_real = d_real.view(batch_size, -1)\n",
        "      d_generated = d_generated.view(batch_size,-1)\n",
        "      real_loss = adversarial_loss(d_real, theoretical_real)\n",
        "      fake_loss = adversarial_loss(d_generated, theoretical_fake)\n",
        "      d_loss = (1/2)* (real_loss + fake_loss)\n",
        "      self.temp_val_d_loss.append(d_loss.data.cpu().numpy())\n",
        "  def _generator_train_iteration(self, y_pred, y_true, train):\n",
        "    # Get generated data\n",
        "    batch_size = y_true.size()[0]\n",
        "    theoretical_real = torch.ones(batch_size,1)\n",
        "    pixel_diff = adversarial_loss(y_true,y_pred)\n",
        "    if self.use_cuda:\n",
        "      theoretical_real = theoretical_real.cuda()\n",
        "    if train:\n",
        "      self.G_opt.zero_grad()\n",
        "      # Calculate loss and optimize\n",
        "      d_generated = self.D(y_pred)\n",
        "      g_loss = 0.5*(adversarial_loss(d_generated,theoretical_real) + pixel_diff)\n",
        "      g_loss.backward()\n",
        "      self.G_opt.step()\n",
        "\n",
        "      # Record loss\n",
        "      g_loss = g_loss.data.cpu().numpy()\n",
        "      self.temp_train_g_loss.append(g_loss)\n",
        "      self.temp_train_mse.append(pixel_diff)\n",
        "    else:\n",
        "\n",
        "      # Calculate loss and optimize\n",
        "      d_generated = self.D(y_pred)\n",
        "      g_loss = 0.5*(adversarial_loss(d_generated, theoretical_real) + pixel_diff)\n",
        "\n",
        "      # Record loss\n",
        "      g_loss = g_loss.data.cpu().numpy()\n",
        "      self.temp_val_g_loss.append(g_loss)\n",
        "      self.temp_val_mse.append(pixel_diff)\n",
        "  def _train_epoch(self,train_loader):\n",
        "\n",
        "    for i, batch_train in enumerate(train_loader):\n",
        "\n",
        "      x_train = batch_train[:,:-1,:,:,:]\n",
        "      y_train = batch_train[:,-1,:,:,:]\n",
        "      if self.use_cuda:\n",
        "        x_train, y_train = x_train.cuda(), y_train.cuda()\n",
        "\n",
        "      n_series = x_train.shape[0]\n",
        "      n_img_in_series = x_train.shape[1]\n",
        "      img_channels = x_train.shape[2]\n",
        "      img_height = x_train.shape[3]\n",
        "      img_width = x_train.shape[4]\n",
        "\n",
        "      x_train_new_dim = (n_series*n_img_in_series, img_channels, img_height, img_width)\n",
        "      x_train = torch.reshape(x_train,x_train_new_dim)\n",
        "      y_train_predict = self.G(x_train)\n",
        "      y_train_crop = fn.center_crop(y_train, output_size=[256])\n",
        "      y_train_predict_crop = fn.center_crop(y_train_predict, output_size = [256])\n",
        "      self._critic_train_iteration(y_train_predict_crop, y_train_crop, train = True)\n",
        "      self._generator_train_iteration(y_train_predict_crop, y_train_crop, train = True)\n",
        "  def _validate(self, val_loader):\n",
        "    self.G.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch_val in val_loader:\n",
        "        x_val = batch_val[:,:-1,:,:,:]\n",
        "        y_val = batch_val[:,-1,:,:,:]\n",
        "        if self.use_cuda:\n",
        "          x_val, y_val = x_val.cuda(), y_val.cuda()\n",
        "\n",
        "\n",
        "        n_series_val = x_val.shape[0]\n",
        "        n_img_in_series_val = x_val.shape[1]\n",
        "        img_channels_val = x_val.shape[2]\n",
        "        img_height_val = x_val.shape[3]\n",
        "        img_width_val = x_val.shape[4]\n",
        "\n",
        "        x_val_new_dim = (n_series_val*n_img_in_series_val, img_channels_val, img_height_val, img_width_val)\n",
        "        x_val = torch.reshape(x_val,x_val_new_dim)\n",
        "\n",
        "        y_val_predict = self.G(x_val)\n",
        "        y_val_crop = fn.center_crop(y_val, output_size=[256])\n",
        "        y_val_predict_crop = fn.center_crop(y_val_predict, output_size = [256])\n",
        "        self._critic_train_iteration(y_val_predict_crop, y_val_crop, train = False)\n",
        "        self._generator_train_iteration(y_val_predict_crop, y_val_crop, train = False)\n",
        "  def train(self, train_loader, start_epochs, n_epochs, validate_loader):\n",
        "    for epoch in range(start_epochs, n_epochs):\n",
        "      self.G.train()\n",
        "      self._train_epoch(train_loader)\n",
        "      self._validate(validate_loader)\n",
        "      avg_train_g_loss = sum(self.temp_train_g_loss) / len(self.temp_train_g_loss)\n",
        "      avg_train_d_loss = sum(self.temp_train_d_loss) / len(self.temp_train_d_loss)\n",
        "      avg_val_g_loss = sum(self.temp_val_g_loss) / len(self.temp_val_g_loss)\n",
        "      avg_val_d_loss = sum(self.temp_val_d_loss) / len(self.temp_val_d_loss)\n",
        "      avg_train_mse = sum(self.temp_train_mse)/len(self.temp_train_mse)\n",
        "      avg_val_mse = sum(self.temp_val_mse)/len(self.temp_val_mse)\n",
        "      if epoch % self.print_every == 0:\n",
        "        print(\"Iteration {}\".format(epoch + 1))\n",
        "        print(\"D: {}\".format(avg_train_d_loss))\n",
        "        print(\"val_D: {}\".format(avg_val_d_loss))\n",
        "        print(\"G: {}\".format(avg_train_d_loss))\n",
        "        print(\"val_G: {}\".format(avg_val_g_loss))\n",
        "        print(\"train_mse:{}\".format(avg_train_mse))\n",
        "        print(\"val_mse:{}\".format(avg_val_mse))\n",
        "\n",
        "      ##############\n",
        "      # checkpoint #\n",
        "      ##############\n",
        "\n",
        "      if self.use_cuda:\n",
        "        self.G, self.D = self.G.cpu(), self.D.cpu()\n",
        "      self.train_g_loss.append(avg_train_g_loss)\n",
        "      self.val_g_loss.append(avg_val_g_loss)\n",
        "      self.train_d_loss.append(avg_train_d_loss)\n",
        "      self.val_d_loss.append(avg_val_d_loss)\n",
        "      self.train_mse.append(avg_train_mse)\n",
        "      self.val_mse.append(avg_val_mse)\n",
        "\n",
        "      curr_val_mse = self.val_mse[-1]\n",
        "      if curr_val_mse <= self.valid_mse_min:\n",
        "        new_valid_mse_min = curr_val_mse\n",
        "      else:\n",
        "        new_valid_mse_min = self.valid_mse_min\n",
        "      checkpoint = {\n",
        "        'epoch': epoch + 1,\n",
        "        'generator_state_dict': self.G.state_dict(),\n",
        "        'generator_optimizer': self.G_opt.state_dict(),\n",
        "        'discriminator_state_dict': self.D.state_dict(),\n",
        "        'discriminator_optimizer': self.D_opt.state_dict(),\n",
        "        'train_mse': self.train_mse,\n",
        "        'val_mse': self.val_mse,\n",
        "        'train_g_loss':self.train_g_loss,\n",
        "        'val_g_loss': self.val_g_loss,\n",
        "        'train_d_loss':self.train_d_loss,\n",
        "        'val_d_loss':self.val_d_loss,\n",
        "        'lowest_val_loss': new_valid_mse_min\n",
        "        }\n",
        "      # save checkpoint\n",
        "      save_ckp(checkpoint, False, self.checkpoint_path,self.best_model_path)\n",
        "      if epoch % self.save_model_every == 0:\n",
        "        backup_path = \"/content/drive/MyDrive/Capstone/Capstone_checkpoint_models/\"+ \"6_clstm_lsgan_\"+str(epoch)+\".pt\"\n",
        "        save_ckp(checkpoint,False , backup_path, self.best_model_path)\n",
        "      # save another copy in case model corrupt\n",
        "      if curr_val_mse <= self.valid_mse_min:\n",
        "          print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(self.valid_mse_min,curr_val_mse))\n",
        "          # save checkpoint as best model\n",
        "          save_ckp(checkpoint, True, self.checkpoint_path, self.best_model_path)\n",
        "          self.valid_mse_min = curr_val_mse\n",
        "      self.temp_train_d_loss = []\n",
        "      self.temp_train_g_loss = []\n",
        "      self.temp_val_d_loss = []\n",
        "      self.temp_val_g_loss = []\n",
        "      self.temp_train_mse = []\n",
        "      self.temp_val_mse = []\n",
        "      if self.use_cuda:\n",
        "        self.G, self.D = self.G.cuda(), self.D.cuda()\n"
      ],
      "metadata": {
        "id": "YJC6g3cUgNJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzdRvV12o8xE"
      },
      "source": [
        "# Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRaE2Ci5o_u6"
      },
      "outputs": [],
      "source": [
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "\n",
        "  f_path = checkpoint_path\n",
        "  torch.save(state, f_path)\n",
        "  if is_best:\n",
        "      print(\"Saving a new best model\")\n",
        "      best_fpath = best_model_path\n",
        "      # copy that checkpoint file to best path given, best_model_path\n",
        "      shutil.copyfile(f_path, best_fpath)\n",
        "  else:\n",
        "    print('Validation does not improve')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLJe-iq3a4PC"
      },
      "outputs": [],
      "source": [
        "def load_ckp(checkpoint_fpath, gen_model, gen_opt, discrim_model, discrim_opt):\n",
        "    \"\"\"\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    model: model that we want to load checkpoint parameters into\n",
        "    optimizer: optimizer we defined in previous training\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\")\n",
        "    # load check point\n",
        "    checkpoint = torch.load(checkpoint_fpath,map_location=\"cuda:0\")\n",
        "    # initialize state_dict from checkpoint to model\n",
        "    gen_model.load_state_dict(checkpoint['generator_state_dict'])\n",
        "    discrim_model.load_state_dict(checkpoint['discriminator_state_dict'])\n",
        "    gen_model = gen_model.to(device)\n",
        "    discrim_model = discrim_model.to(device)\n",
        "    # initialize optimizer from checkpoint to optimizer\n",
        "    gen_opt.load_state_dict(checkpoint['generator_optimizer'])\n",
        "    discrim_opt.load_state_dict(checkpoint['discriminator_optimizer'])\n",
        "\n",
        "    train_mse = checkpoint['train_mse']\n",
        "    val_mse = checkpoint['val_mse']\n",
        "    train_g_loss = checkpoint['train_g_loss']\n",
        "    val_g_loss = checkpoint['val_g_loss']\n",
        "\n",
        "    train_d_loss = checkpoint['train_d_loss']\n",
        "    val_d_loss = checkpoint['val_d_loss']\n",
        "\n",
        "    lowest_val_loss = checkpoint['lowest_val_loss']\n",
        "\n",
        "    # return model, optimizer, epoch value, min validation loss\n",
        "    return checkpoint['epoch'], gen_model, discrim_model, gen_opt, discrim_opt, train_mse,val_mse,train_g_loss,val_g_loss,train_d_loss,val_d_loss,lowest_val_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6EnGnLFgnke"
      },
      "source": [
        "# Setting Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Datapoint"
      ],
      "metadata": {
        "id": "Y8-QBpuuPRsf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tjffzEIWfQk"
      },
      "outputs": [],
      "source": [
        "# convert the image to array\n",
        "x_img_length = 2\n",
        "\n",
        "x_arr = np.zeros(shape=(100,x_img_length, 3,288,432), dtype=np.uint8)\n",
        "y_arr = np.zeros(shape=(100,1,3,288,432), dtype=np.uint8)\n",
        "\n",
        "# series, how many image in a series, channel size, image width, image height\n",
        "\n",
        "for i in range(100): # loop through 100 series\n",
        "  for j in range(x_img_length): # loop through images within series\n",
        "    model_path = \"/content/drive/MyDrive/Capstone/Capstone_data_jpg/\"+str(i)\n",
        "    x_to_convert = Image.open(model_path+'/'+\"{:02d}\".format(j)+'im.jpg')\n",
        "    x = np.asarray(x_to_convert)\n",
        "    x = np.moveaxis(x,-1,0) # change image dimension to channel first\n",
        "    x_arr[i][j] = x\n",
        "  y_to_convert = Image.open(model_path+'/'+\"{:02d}\".format(x_img_length+1)+'im.jpg')\n",
        "  y = np.asarray(y_to_convert)\n",
        "  y = np.moveaxis(y,-1,0) # change image dimension to channel first\n",
        "  y_arr[i][0] = y\n",
        "\n",
        "# image dimention\n",
        "n_series = x_arr.shape[0]\n",
        "n_img_in_series = x_arr.shape[1]\n",
        "img_channels = x_arr.shape[2]\n",
        "img_height = x_arr.shape[3]\n",
        "img_width = x_arr.shape[4]\n",
        "\n",
        "# train/validation/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_arr, y_arr, test_size = 0.2, random_state = 1)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5, random_state = 1)\n",
        "\n",
        "num_train_data = X_train.shape[0]\n",
        "num_val_data = X_val.shape[0]\n",
        "num_test_data = X_test.shape[0]\n",
        "\n",
        "# generating means and std for normalization\n",
        "trans_X_train= torch.tensor((np.array(X_train)/255).astype(np.float32))\n",
        "trans_y_train = torch.tensor((np.array(y_train)/255).astype(np.float32))\n",
        "trans_X_val = torch.tensor((np.array(X_val)/255).astype(np.float32))\n",
        "trans_y_val = torch.tensor((np.array(y_val)/255).astype(np.float32))\n",
        "trans_X_test = torch.tensor((np.array(X_test)/255).astype(np.float32))\n",
        "trans_y_test = torch.tensor((np.array(y_test)/255).astype(np.float32))\n",
        "\n",
        "\n",
        "# final train/val/test data\n",
        "final_train_data = torch.cat((trans_X_train, trans_y_train), dim = 1)\n",
        "final_val_data = torch.cat((trans_X_val,trans_y_val),dim = 1)\n",
        "final_test_data = torch.cat((trans_X_test,trans_y_test),dim = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQxYsRndGPq9"
      },
      "outputs": [],
      "source": [
        "batch_train_num = 8\n",
        "batch_valid_num = 10\n",
        "batch_test_num= 10\n",
        "\n",
        "train_dl = DataLoader(final_train_data, batch_train_num, shuffle = True)\n",
        "val_dl = DataLoader(final_val_data, batch_valid_num, shuffle = True)\n",
        "test_dl = DataLoader(final_test_data, batch_test_num, shuffle = False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling Train"
      ],
      "metadata": {
        "id": "dYdY3hzjPXXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "# setting parameters\n",
        "\n",
        "img_length = x_img_length\n",
        "clstm = CLSTM(512)\n",
        "img_size = (288, 432, 3)\n",
        "discriminator = Discriminator(img_size=img_size, dim=16)\n",
        "print(clstm)\n",
        "print(discriminator)\n",
        "\n",
        "# Initialize optimizers\n",
        "lr = 0.00001\n",
        "\n",
        "adversarial_loss = torch.nn.MSELoss()\n",
        "g_optimizer = optim.RMSprop(clstm.parameters(), lr = lr)\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr = lr)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "train_mse =[]\n",
        "val_mse =[]\n",
        "train_g_loss =[]\n",
        "val_g_loss =[]\n",
        "train_d_loss =[]\n",
        "val_d_loss =[]\n",
        "valid_mse_min = np.Inf\n",
        "start_epochs = 0\n",
        "n_epochs = 800\n",
        "save_model_every = 100\n",
        "checkpoint_path = \"/content/drive/MyDrive/Capstone/Capstone_checkpoint_models/6_clstm_lsgan_final.pt\"\n",
        "best_model_path = \"/content/drive/MyDrive/Capstone/Capstone_models/6_clstm_lsgan_final.pt\"\n",
        "\n",
        "\n",
        "trainer = Trainer(clstm, discriminator, g_optimizer, d_optimizer, train_mse,\n",
        "               val_mse, train_g_loss,val_g_loss,train_d_loss,val_d_loss,checkpoint_path,\n",
        "                  best_model_path, save_model_every, valid_mse_min, print_every = 10, use_cuda=torch.cuda.is_available())\n"
      ],
      "metadata": {
        "id": "-0uvMcnLWAVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c1a7d95-437f-436f-c54f-a15344a72419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLSTM(\n",
            "  (encoder): Encoder(\n",
            "    (convNN): ConvNN(\n",
            "      (network): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (5): ReLU()\n",
            "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (7): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "        (8): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (9): ReLU()\n",
            "        (10): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (11): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "        (12): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (13): ReLU()\n",
            "        (14): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (15): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "        (16): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (17): ReLU()\n",
            "        (18): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (lstm): LSTM(512, 512, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (main): Sequential(\n",
            "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "      (1): ReLU()\n",
            "      (2): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (4): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (5): ReLU()\n",
            "      (6): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (8): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (9): ReLU()\n",
            "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (12): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (13): ReLU()\n",
            "      (14): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (16): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (17): Sigmoid()\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Discriminator(\n",
            "  (image_to_features): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): LeakyReLU(negative_slope=0.2)\n",
            "    (4): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "    (6): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (7): LeakyReLU(negative_slope=0.2)\n",
            "    (8): Conv2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (9): Sigmoid()\n",
            "  )\n",
            "  (features_to_prob): Sequential(\n",
            "    (0): Linear(in_features=192, out_features=1, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.train(train_dl, start_epochs,  n_epochs, val_dl)"
      ],
      "metadata": {
        "id": "-TEq1YC0jQ57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2k-9tnynux6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f43478-5e4b-4197-a69e-4de7d65838e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLSTM(\n",
            "  (encoder): Encoder(\n",
            "    (convNN): ConvNN(\n",
            "      (network): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (5): ReLU()\n",
            "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (7): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "        (8): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (9): ReLU()\n",
            "        (10): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (11): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "        (12): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (13): ReLU()\n",
            "        (14): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "        (15): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "        (16): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (17): ReLU()\n",
            "        (18): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (lstm): LSTM(512, 512, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (main): Sequential(\n",
            "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "      (1): ReLU()\n",
            "      (2): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (4): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (5): ReLU()\n",
            "      (6): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (8): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (9): ReLU()\n",
            "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (12): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (13): ReLU()\n",
            "      (14): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (16): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (17): Sigmoid()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# loading checkpoint if model fail\n",
        "ckp_path = \"/content/drive/MyDrive/Capstone/Capstone_checkpoint_models/6_clstm_lsgan_final.pt\"\n",
        "\n",
        "clstm = CLSTM(512)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "img_size = (288, 432, 3)\n",
        "discriminator = Discriminator(img_size=img_size, dim=16)\n",
        "# Initialize optimizers\n",
        "lr = 0.00001\n",
        "\n",
        "adversarial_loss = torch.nn.MSELoss()\n",
        "g_optimizer = optim.RMSprop(clstm.parameters(), lr = lr)\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr = lr)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "batch_train_num = 8\n",
        "batch_valid_num = 10\n",
        "batch_test_num= 10\n",
        "\n",
        "img_length = x_img_length\n",
        "\n",
        "start_epoch, g_model, d_model, g_opt, d_opt, train_mse,val_mse,train_g_loss,val_g_loss,train_d_loss,val_d_loss,lowest_val_loss = load_ckp(ckp_path, clstm, g_optimizer,discriminator,d_optimizer)\n",
        "print(g_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# continue training\n",
        "\n",
        "n_epochs = 1000\n",
        "checkpoint_path = \"/content/drive/MyDrive/Capstone/Capstone_checkpoint_models/6_clstm_lsgan_final.pt\"\n",
        "best_model_path = \"/content/drive/MyDrive/Capstone/Capstone_models/6_clstm_lsgan_final.pt\"\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "trainer = Trainer(clstm, discriminator, g_optimizer, d_optimizer, train_mse,\n",
        "               val_mse, train_g_loss,val_g_loss,train_d_loss,val_d_loss,checkpoint_path,\n",
        "                  best_model_path, save_model_every, lowest_val_loss, print_every = 10, use_cuda=torch.cuda.is_available())\n",
        "\n"
      ],
      "metadata": {
        "id": "_z7534xPVpos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.train(train_dl, start_epoch,  n_epochs, val_dl)"
      ],
      "metadata": {
        "id": "xvedS_DM03qx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
