{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mengmengwoo/CNN-LSTM-GAN/blob/main/CNN_LSTM_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Author\n",
        "- **Meng-Hsuan (Michelle) Wu** (JHU)\n",
        "\n",
        "## Projects\n",
        "- CNN-LSTM with MSE loss"
      ],
      "metadata": {
        "id": "8eKizqUW0z4L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K7SIv-uw7Qt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os.path\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as fn\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import math\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import pickle\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuBvBJC6eBds"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwFE4LdpgCBf"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT2jjM9ogDhT"
      },
      "outputs": [],
      "source": [
        "class ConvNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size = 2, stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(64,momentum=0.9),\n",
        "        nn.MaxPool2d(2),\n",
        "\n",
        "        nn.Conv2d(64, 128, kernel_size = 3, stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(128,momentum=0.9),\n",
        "        nn.MaxPool2d(3),\n",
        "\n",
        "        nn.Conv2d(128, 256, kernel_size = 2, stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(256,momentum=0.9),\n",
        "        nn.MaxPool2d(3),\n",
        "\n",
        "        nn.Conv2d(256, 256, kernel_size = 2, stride = 1),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.BatchNorm2d(256,momentum=0.9),\n",
        "        nn.MaxPool2d(3),\n",
        "\n",
        "        nn.Conv2d(256, 512, kernel_size = 3, stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    cnn_val = self.network(x)\n",
        "    return_val = F.max_pool2d(cnn_val, kernel_size=cnn_val.size()[2:])\n",
        "    return_val = torch.squeeze(return_val)\n",
        "    return return_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H55vd3TYgkv2"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.convNN = ConvNN()\n",
        "    self.lstm = nn.LSTM(input_size = 512, hidden_size = 512,\n",
        "                        batch_first = True, bidirectional = True,\n",
        "                        num_layers = 4, dropout = 0.2)\n",
        "\n",
        "  def forward(self, input):\n",
        "    batch_size = int(input.shape[0]/img_length)\n",
        "\n",
        "    in_features = self.convNN(input)\n",
        "    in_features = torch.reshape(in_features,(batch_size, img_length, 512))\n",
        "    output, (h_n, c_n) = self.lstm(in_features)\n",
        "    return h_n[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdaXG3I5f7u4"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aK6ivYlugAZ0"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels = 512, out_channels = 256,\n",
        "                               kernel_size = 4, stride = 1, padding = 0,\n",
        "                               bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "            nn.BatchNorm2d(256),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "            nn.BatchNorm2d(128),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 128, 4, 2, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "            nn.BatchNorm2d(128),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "            nn.BatchNorm2d(64),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
        "            nn.Sigmoid()\n",
        "\n",
        "        )\n",
        "    def forward(self, input):\n",
        "      return self.main(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TesEADzsglMZ"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4adeccjTJyv"
      },
      "outputs": [],
      "source": [
        "class CLSTM(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CLSTM, self).__init__()\n",
        "    self.encoder = Encoder()\n",
        "    self.decoder = Decoder()\n",
        "  def forward(self, x):\n",
        "    y_hidden = self.encoder(x)\n",
        "    y_hidden = torch.unsqueeze(y_hidden,2)\n",
        "    y_hidden = torch.unsqueeze(y_hidden,3)\n",
        "    y_predict = self.decoder(y_hidden)\n",
        "    return y_predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmHw4HIvkSaR"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sj0zJrn1kQ_Y"
      },
      "outputs": [],
      "source": [
        "def train(start_epochs,n_epochs, train_loader, val_loader, img_length,\n",
        "          valid_loss_min_input, checkpoint_path,best_model_path,model,\n",
        "          criterion,opt_function, train_history_lst, val_history_lst,use_cuda\n",
        "          ):\n",
        "\n",
        "  train_history = train_history_lst\n",
        "  val_history = val_history_lst\n",
        "\n",
        "  # initialize tracker for minimum validation loss\n",
        "  valid_loss_min = valid_loss_min_input\n",
        "  for epoch in range(start_epochs, n_epochs+1):\n",
        "\n",
        "    ####################\n",
        "    # training process #\n",
        "    ####################\n",
        "    model.train()\n",
        "    train_loss_lst = []\n",
        "    for batch_train in train_loader:\n",
        "\n",
        "      x_train = batch_train[:,:-1,:,:,:]\n",
        "      y_train = batch_train[:,-1,:,:,:]\n",
        "      if use_cuda:\n",
        "        x_train, y_train = x_train.cuda(), y_train.cuda()\n",
        "\n",
        "      n_series = x_train.shape[0]\n",
        "      n_img_in_series = x_train.shape[1]\n",
        "      img_channels = x_train.shape[2]\n",
        "      img_height = x_train.shape[3]\n",
        "      img_width = x_train.shape[4]\n",
        "\n",
        "      x_train_new_dim = (n_series*n_img_in_series, img_channels, img_height, img_width)\n",
        "      x_train = torch.reshape(x_train,x_train_new_dim)\n",
        "\n",
        "      y_train_predict = model(x_train)\n",
        "      y_train_crop = fn.center_crop(y_train, output_size=[256])\n",
        "      y_train_predict = fn.center_crop(y_train_predict, output_size =[256])\n",
        "      train_loss = criterion(y_train_predict,y_train_crop) # train the model and calculate mse loss\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      train_loss.backward() # backpropogation\n",
        "      optimizer.step() # update the weight for the model\n",
        "      train_loss_lst.append(train_loss.cpu().detach().numpy())\n",
        "\n",
        "    avg_train_loss = sum(train_loss_lst)/len(train_loss_lst)\n",
        "    train_history.append(avg_train_loss)\n",
        "\n",
        "    ######################\n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      tot_val_loss = 0\n",
        "      val_loss_lst = []\n",
        "      for batch_val in val_loader:\n",
        "        x_val = batch_val[:,:-1,:,:,:]\n",
        "        y_val = batch_val[:,-1,:,:,:]\n",
        "        if use_cuda:\n",
        "          x_val, y_val = x_val.cuda(), y_val.cuda()\n",
        "\n",
        "\n",
        "        n_series_val = x_val.shape[0]\n",
        "        n_img_in_series_val = x_val.shape[1]\n",
        "        img_channels_val = x_val.shape[2]\n",
        "        img_height_val = x_val.shape[3]\n",
        "        img_width_val = x_val.shape[4]\n",
        "\n",
        "        x_val_new_dim = (n_series_val*n_img_in_series_val, img_channels_val, img_height_val, img_width_val)\n",
        "        x_val = torch.reshape(x_val,x_val_new_dim)\n",
        "\n",
        "        y_val_predict = model(x_val)\n",
        "        y_val_crop = fn.center_crop(y_val, output_size=[256])\n",
        "        y_val_predict = fn.center_crop(y_val_predict, output_size =[256])\n",
        "        val_loss = criterion(y_val_predict, y_val_crop)\n",
        "        val_loss_lst.append(val_loss.cpu().numpy())\n",
        "      avg_val_loss = sum(val_loss_lst)/len(val_loss_lst)\n",
        "      avg_val_loss_np = avg_val_loss\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch+1, avg_train_loss,avg_val_loss))\n",
        "    val_history.append(avg_val_loss_np)\n",
        "\n",
        "    # create checkpoint variable and add important data\n",
        "    checkpoint = {\n",
        "        'epoch': epoch + 1,\n",
        "        'valid_loss_min': avg_val_loss,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'train_history': train_history,\n",
        "        'val_history': val_history\n",
        "    }\n",
        "    # save checkpoint\n",
        "    save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
        "\n",
        "    # save the model if validation loss has decreased\n",
        "    if avg_val_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,avg_val_loss))\n",
        "        # save checkpoint as best model\n",
        "        save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "        valid_loss_min = avg_val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzdRvV12o8xE"
      },
      "source": [
        "# Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRaE2Ci5o_u6"
      },
      "outputs": [],
      "source": [
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "  f_path = checkpoint_path\n",
        "  torch.save(state, f_path)\n",
        "  if is_best:\n",
        "      print(\"Saving a new best model\")\n",
        "      best_fpath = best_model_path\n",
        "      shutil.copyfile(f_path, best_fpath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLJe-iq3a4PC"
      },
      "outputs": [],
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "\n",
        "    # load check point\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "\n",
        "    # initialize state_dict from checkpoint to model\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "    # initialize optimizer from checkpoint to optimizer\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
        "    valid_loss_min = checkpoint['valid_loss_min']\n",
        "    train_loss_lst = checkpoint['train_history']\n",
        "    val_loss_lst = checkpoint['val_history']\n",
        "\n",
        "    # return model, optimizer, epoch value, min validation loss\n",
        "    return model, optimizer, checkpoint['epoch'], valid_loss_min.item(), train_loss_lst,val_loss_lst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6EnGnLFgnke"
      },
      "source": [
        "# Setting Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaI6mF4k41CP"
      },
      "outputs": [],
      "source": [
        "# setting parameters\n",
        "model = CLSTM()\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "start_epochs = 0\n",
        "num_epochs = 1000\n",
        "batch_train_num = 16\n",
        "batch_valid_num = 4\n",
        "batch_test_num= 10\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.RMSprop(model.parameters(), lr = 0.00001)\n",
        "ngf = 64\n",
        "nz = 100\n",
        "nc = 3\n",
        "img_length = 2 # how many images per series I extract\n",
        "checkpoint_dir = \"/content/drive/MyDrive/Capstone/Capstone_checkpoint_models/clstm_checkpoint_mse_final.pt\"\n",
        "best_model_dir = \"/content/drive/MyDrive/Capstone/Capstone_models/clstm_best_model_mse_final.pt\"\n",
        "valid_loss_min_input = np.Inf\n",
        "train_history_lst = []\n",
        "val_history_lst = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Datapoint"
      ],
      "metadata": {
        "id": "Y8-QBpuuPRsf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tjffzEIWfQk"
      },
      "outputs": [],
      "source": [
        "# convert the image to array\n",
        "\n",
        "x_arr = np.zeros(shape=(100,2, 3,288,432))\n",
        "y_arr = np.zeros(shape=(100,1,3,288,432))\n",
        "\n",
        "\n",
        "for i in range(100): # loop through 100 series\n",
        "  for j in range(img_length): # loop through images within series\n",
        "    model_path = \"/content/drive/MyDrive/Capstone/Capstone_data_jpg/\"+str(i)\n",
        "    x_to_convert = Image.open(model_path+'/'+\"{:02d}\".format(j)+'im.jpg')\n",
        "    x = np.asarray(x_to_convert)\n",
        "    x = np.moveaxis(x,-1,0) # change image dimension to channel first\n",
        "    x_arr[[i,j]] = x\n",
        "  y_to_convert = Image.open(model_path+'/'+\"{:02d}\".format(img_length+1)+'im.jpg')\n",
        "  y = np.asarray(y_to_convert)\n",
        "  y = np.moveaxis(y,-1,0) # change image dimension to channel first\n",
        "  y_arr[[i,0]] = y\n",
        "\n",
        "# image dimention\n",
        "n_series = x_arr.shape[0]\n",
        "n_img_in_series = x_arr.shape[1]\n",
        "img_channels = x_arr.shape[2]\n",
        "img_height = x_arr.shape[3]\n",
        "img_width = x_arr.shape[4]\n",
        "\n",
        "# train/validation/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_arr, y_arr, test_size = 0.2, random_state = 1)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5, random_state = 1)\n",
        "\n",
        "num_train_data = X_train.shape[0]\n",
        "num_val_data = X_val.shape[0]\n",
        "num_test_data = X_test.shape[0]\n",
        "\n",
        "# generating means and std for normalization\n",
        "trans_X_train= torch.tensor((np.array(X_train)/255).astype(np.float32))\n",
        "trans_y_train = torch.tensor((np.array(y_train)/255).astype(np.float32))\n",
        "trans_X_val = torch.tensor((np.array(X_val)/255).astype(np.float32))\n",
        "trans_y_val = torch.tensor((np.array(y_val)/255).astype(np.float32))\n",
        "trans_X_test = torch.tensor((np.array(X_test)/255).astype(np.float32))\n",
        "trans_y_test = torch.tensor((np.array(y_test)/255).astype(np.float32))\n",
        "\n",
        "\n",
        "# final train/val/test data\n",
        "final_train_data = torch.cat((trans_X_train, trans_y_train), dim = 1)\n",
        "final_val_data = torch.cat((trans_X_val,trans_y_val),dim = 1)\n",
        "final_test_data = torch.cat((trans_X_test,trans_y_test),dim = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQxYsRndGPq9"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(final_train_data, batch_train_num, shuffle = True)\n",
        "val_dl = DataLoader(final_val_data, batch_valid_num, shuffle = True)\n",
        "test_dl = DataLoader(final_test_data, batch_test_num, shuffle = False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling Train"
      ],
      "metadata": {
        "id": "dYdY3hzjPXXf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRNQc6N7IFHj"
      },
      "outputs": [],
      "source": [
        "# fitting data to models\n",
        "# train(start_epochs,num_epochs, train_dl, val_dl, img_length,\n",
        "#                       valid_loss_min_input, checkpoint_dir, best_model_dir, model,\n",
        "#                       criterion, optimizer, train_history_lst, val_history_lst, use_cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2k-9tnynux6"
      },
      "outputs": [],
      "source": [
        "# loading checkpoint if model fail\n",
        "ckp_path = \"/content/drive/MyDrive/Capstone/Capstone_checkpoint_models/clstm_checkpoint_mse_final.pt\"\n",
        "optimizer = optim.RMSprop(model.parameters(), lr = 0.00001)\n",
        "model, optimizer, start_epoch, valid_loss_min, train_lst, val_lst = load_ckp(ckp_path, model, optimizer)\n",
        "\n",
        "print(\"model = \", model)\n",
        "print(\"optimizer = \", optimizer)\n",
        "print(\"start_epoch = \", start_epoch)\n",
        "print(\"train_lst = \",train_lst)\n",
        "print(\"validation_lst = \",val_lst)\n",
        "print(\"valid_loss_min = \", valid_loss_min)\n",
        "print(\"valid_loss_min = {:.6f}\".format(valid_loss_min))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train(start_epoch,num_epochs, train_dl, val_dl, img_length,\n",
        "#                       valid_loss_min, ckp_path, best_model_dir, model,\n",
        "#                       criterion, optimizer, train_lst, val_lst, use_cuda)"
      ],
      "metadata": {
        "id": "ryBEM7MJ0_3Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}